{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03e52f0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-19T22:38:28.905892Z",
     "iopub.status.busy": "2022-03-19T22:38:28.905186Z",
     "iopub.status.idle": "2022-03-19T22:38:29.575225Z",
     "shell.execute_reply": "2022-03-19T22:38:29.574663Z",
     "shell.execute_reply.started": "2022-03-19T22:28:15.451201Z"
    },
    "papermill": {
     "duration": 0.708202,
     "end_time": "2022-03-19T22:38:29.575387",
     "exception": false,
     "start_time": "2022-03-19T22:38:28.867185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test  train  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../input/humpback-whale-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43f9ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:38:29.633388Z",
     "iopub.status.busy": "2022-03-19T22:38:29.632622Z",
     "iopub.status.idle": "2022-03-19T22:38:30.323597Z",
     "shell.execute_reply": "2022-03-19T22:38:30.324257Z",
     "shell.execute_reply.started": "2022-03-19T22:28:16.134511Z"
    },
    "papermill": {
     "duration": 0.722379,
     "end_time": "2022-03-19T22:38:30.324501",
     "exception": false,
     "start_time": "2022-03-19T22:38:29.602122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image,Id\r\n",
      "0000e88ab.jpg,w_f48451c\r\n",
      "0001f9222.jpg,w_c3d896a\r\n",
      "00029d126.jpg,w_20df2c5\r\n",
      "00050a15a.jpg,new_whale\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 5 ../input/humpback-whale-identification/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3496d920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:38:30.419793Z",
     "iopub.status.busy": "2022-03-19T22:38:30.418950Z",
     "iopub.status.idle": "2022-03-19T22:38:31.787235Z",
     "shell.execute_reply": "2022-03-19T22:38:31.786279Z",
     "shell.execute_reply.started": "2022-03-19T22:28:16.808753Z"
    },
    "papermill": {
     "duration": 1.420728,
     "end_time": "2022-03-19T22:38:31.787416",
     "exception": false,
     "start_time": "2022-03-19T22:38:30.366688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf ./train\n",
    "! mkdir ./train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbe6bf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:38:31.850337Z",
     "iopub.status.busy": "2022-03-19T22:38:31.849770Z",
     "iopub.status.idle": "2022-03-19T22:41:59.138153Z",
     "shell.execute_reply": "2022-03-19T22:41:59.137668Z",
     "shell.execute_reply.started": "2022-03-19T22:28:18.120863Z"
    },
    "papermill": {
     "duration": 207.322916,
     "end_time": "2022-03-19T22:41:59.138345",
     "exception": false,
     "start_time": "2022-03-19T22:38:31.815429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "known_ids = {}\n",
    "with open('../input/humpback-whale-identification/train.csv', 'r') as infile:\n",
    "    rdr = csv.reader(infile)\n",
    "    for row in rdr:\n",
    "        img = row[0]\n",
    "        id = row[1]\n",
    "        if id == 'Id':\n",
    "            continue\n",
    "        if id not in known_ids:\n",
    "            os.mkdir('./train/' + id)\n",
    "            known_ids[id] = True\n",
    "        shutil.copy('../input/humpback-whale-identification/train/' + img, './train/' + id + '/' + img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4bd12ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:41:59.240128Z",
     "iopub.status.busy": "2022-03-19T22:41:59.239357Z",
     "iopub.status.idle": "2022-03-19T22:42:00.033693Z",
     "shell.execute_reply": "2022-03-19T22:42:00.032865Z",
     "shell.execute_reply.started": "2022-03-19T22:31:55.407637Z"
    },
    "papermill": {
     "duration": 0.850286,
     "end_time": "2022-03-19T22:42:00.033830",
     "exception": false,
     "start_time": "2022-03-19T22:41:59.183544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\t      docs\t\t\t   requirements.txt\r\n",
      "MANIFEST.in\t      hubconf.py\t\t   results\r\n",
      "README.md\t      inference.py\t\t   setup.cfg\r\n",
      "avg_checkpoints.py    mkdocs.yml\t\t   setup.py\r\n",
      "benchmark.py\t      model-index.yml\t\t   tests\r\n",
      "clean_checkpoint.py   notebooks\t\t\t   timm\r\n",
      "convert\t\t      requirements-docs.txt\t   train.py\r\n",
      "distributed_train.sh  requirements-modelindex.txt  validate.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../input/timmmaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc9295b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:00.093074Z",
     "iopub.status.busy": "2022-03-19T22:42:00.092546Z",
     "iopub.status.idle": "2022-03-19T22:42:03.416066Z",
     "shell.execute_reply": "2022-03-19T22:42:03.416541Z",
     "shell.execute_reply.started": "2022-03-19T22:31:56.081532Z"
    },
    "papermill": {
     "duration": 3.355439,
     "end_time": "2022-03-19T22:42:03.416714",
     "exception": false,
     "start_time": "2022-03-19T22:42:00.061275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on https://www.kaggle.com/piantic/how-to-finetuning-models-pytorch-xla-tpu\n",
    "import sys\n",
    "sys.path.append('../input/timmmaster')\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af62f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:03.563030Z",
     "iopub.status.busy": "2022-03-19T22:42:03.561525Z",
     "iopub.status.idle": "2022-03-19T22:42:03.563635Z",
     "shell.execute_reply": "2022-03-19T22:42:03.564045Z",
     "shell.execute_reply.started": "2022-03-19T22:31:59.672416Z"
    },
    "papermill": {
     "duration": 0.118694,
     "end_time": "2022-03-19T22:42:03.564173",
     "exception": false,
     "start_time": "2022-03-19T22:42:03.445479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b590b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:03.624442Z",
     "iopub.status.busy": "2022-03-19T22:42:03.623726Z",
     "iopub.status.idle": "2022-03-19T22:42:03.875766Z",
     "shell.execute_reply": "2022-03-19T22:42:03.875260Z",
     "shell.execute_reply.started": "2022-03-19T22:31:59.678727Z"
    },
    "papermill": {
     "duration": 0.284615,
     "end_time": "2022-03-19T22:42:03.875881",
     "exception": false,
     "start_time": "2022-03-19T22:42:03.591266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.RandomResizedCrop(256, [0.8, 1.2]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "allimg = datasets.ImageFolder('./train', transform=transform)\n",
    "\n",
    "validation_split = 0.15\n",
    "dataset_size = len(allimg)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "np.random.seed(101)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdddbc05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:03.934723Z",
     "iopub.status.busy": "2022-03-19T22:42:03.934171Z",
     "iopub.status.idle": "2022-03-19T22:42:03.937807Z",
     "shell.execute_reply": "2022-03-19T22:42:03.937248Z",
     "shell.execute_reply.started": "2022-03-19T22:31:59.939254Z"
    },
    "papermill": {
     "duration": 0.034651,
     "end_time": "2022-03-19T22:42:03.937918",
     "exception": false,
     "start_time": "2022-03-19T22:42:03.903267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(allimg, batch_size=16, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(allimg, batch_size=16,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77bab84b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:04.000467Z",
     "iopub.status.busy": "2022-03-19T22:42:03.999697Z",
     "iopub.status.idle": "2022-03-19T22:42:04.001997Z",
     "shell.execute_reply": "2022-03-19T22:42:04.001609Z",
     "shell.execute_reply.started": "2022-03-19T22:31:59.946013Z"
    },
    "papermill": {
     "duration": 0.036469,
     "end_time": "2022-03-19T22:42:04.002102",
     "exception": false,
     "start_time": "2022-03-19T22:42:03.965633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name, target_size, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def freeze(self):\n",
    "        # To freeze the residual layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b4fd44a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:04.072673Z",
     "iopub.status.busy": "2022-03-19T22:42:04.062375Z",
     "iopub.status.idle": "2022-03-19T22:42:04.094174Z",
     "shell.execute_reply": "2022-03-19T22:42:04.093791Z",
     "shell.execute_reply.started": "2022-03-19T22:31:59.957465Z"
    },
    "papermill": {
     "duration": 0.065684,
     "end_time": "2022-03-19T22:42:04.094286",
     "exception": false,
     "start_time": "2022-03-19T22:42:04.028602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_whale': 0,\n",
       " 'w_0003639': 1,\n",
       " 'w_0003c59': 2,\n",
       " 'w_0027efa': 3,\n",
       " 'w_00289b1': 4,\n",
       " 'w_002c810': 5,\n",
       " 'w_0032a46': 6,\n",
       " 'w_003bae6': 7,\n",
       " 'w_00656c0': 8,\n",
       " 'w_0066399': 9,\n",
       " 'w_007fefa': 10,\n",
       " 'w_00904a7': 11,\n",
       " 'w_009c9c5': 12,\n",
       " 'w_00a41ba': 13,\n",
       " 'w_00b3dc2': 14,\n",
       " 'w_00d50c9': 15,\n",
       " 'w_00d5466': 16,\n",
       " 'w_00d5e98': 17,\n",
       " 'w_00f340d': 18,\n",
       " 'w_010f858': 19,\n",
       " 'w_0115c24': 20,\n",
       " 'w_0118bab': 21,\n",
       " 'w_012678c': 22,\n",
       " 'w_0135f5f': 23,\n",
       " 'w_0140c92': 24,\n",
       " 'w_015a4bf': 25,\n",
       " 'w_016f0ea': 26,\n",
       " 'w_0182687': 27,\n",
       " 'w_0189b6d': 28,\n",
       " 'w_01976db': 29,\n",
       " 'w_01a1d88': 30,\n",
       " 'w_01cb0c4': 31,\n",
       " 'w_01cbbbd': 32,\n",
       " 'w_01d790e': 33,\n",
       " 'w_01e1b97': 34,\n",
       " 'w_01e1fe0': 35,\n",
       " 'w_01ed442': 36,\n",
       " 'w_01f14e1': 37,\n",
       " 'w_01fc429': 38,\n",
       " 'w_02156b0': 39,\n",
       " 'w_022b708': 40,\n",
       " 'w_022d2f5': 41,\n",
       " 'w_02469a1': 42,\n",
       " 'w_02545ea': 43,\n",
       " 'w_025911c': 44,\n",
       " 'w_0277a07': 45,\n",
       " 'w_027f528': 46,\n",
       " 'w_0292e15': 47,\n",
       " 'w_02aa597': 48,\n",
       " 'w_02c7e9d': 49,\n",
       " 'w_02d138d': 50,\n",
       " 'w_02d5c46': 51,\n",
       " 'w_02e8199': 52,\n",
       " 'w_02ff6d6': 53,\n",
       " 'w_0301302': 54,\n",
       " 'w_030ac9b': 55,\n",
       " 'w_030c8b0': 56,\n",
       " 'w_030e2cf': 57,\n",
       " 'w_03193e5': 58,\n",
       " 'w_031e1a3': 59,\n",
       " 'w_0323574': 60,\n",
       " 'w_03270e3': 61,\n",
       " 'w_0350bf4': 62,\n",
       " 'w_03670aa': 63,\n",
       " 'w_0369a5c': 64,\n",
       " 'w_036bc54': 65,\n",
       " 'w_036dbd0': 66,\n",
       " 'w_037b23f': 67,\n",
       " 'w_038dfc0': 68,\n",
       " 'w_038e5c3': 69,\n",
       " 'w_03a82c1': 70,\n",
       " 'w_03ad89c': 71,\n",
       " 'w_03e3e5e': 72,\n",
       " 'w_03ea6f9': 73,\n",
       " 'w_04003e9': 74,\n",
       " 'w_042b547': 75,\n",
       " 'w_0470377': 76,\n",
       " 'w_04713fd': 77,\n",
       " 'w_04738c8': 78,\n",
       " 'w_048bc73': 79,\n",
       " 'w_049ae2e': 80,\n",
       " 'w_04acf95': 81,\n",
       " 'w_04c9b23': 82,\n",
       " 'w_04d1c8c': 83,\n",
       " 'w_04d4568': 84,\n",
       " 'w_04de239': 85,\n",
       " 'w_04ebfe8': 86,\n",
       " 'w_04f5a19': 87,\n",
       " 'w_04f5f55': 88,\n",
       " 'w_05081a8': 89,\n",
       " 'w_0513962': 90,\n",
       " 'w_051764c': 91,\n",
       " 'w_0531ad5': 92,\n",
       " 'w_0532483': 93,\n",
       " 'w_054162a': 94,\n",
       " 'w_05669fe': 95,\n",
       " 'w_056710d': 96,\n",
       " 'w_056913a': 97,\n",
       " 'w_0577ccc': 98,\n",
       " 'w_059d9e0': 99,\n",
       " 'w_05b4b0c': 100,\n",
       " 'w_05bf34e': 101,\n",
       " 'w_05cc23c': 102,\n",
       " 'w_05d52d0': 103,\n",
       " 'w_05d65b9': 104,\n",
       " 'w_05eb863': 105,\n",
       " 'w_05f8c99': 106,\n",
       " 'w_05fbf14': 107,\n",
       " 'w_060ec6d': 108,\n",
       " 'w_06150e1': 109,\n",
       " 'w_06292cd': 110,\n",
       " 'w_0630c3e': 111,\n",
       " 'w_06313c8': 112,\n",
       " 'w_063282e': 113,\n",
       " 'w_0637181': 114,\n",
       " 'w_06376db': 115,\n",
       " 'w_06460d7': 116,\n",
       " 'w_06471d5': 117,\n",
       " 'w_0655608': 118,\n",
       " 'w_0655a0d': 119,\n",
       " 'w_065ee1b': 120,\n",
       " 'w_06619ff': 121,\n",
       " 'w_066ac1a': 122,\n",
       " 'w_066ddc5': 123,\n",
       " 'w_068baa8': 124,\n",
       " 'w_06935ed': 125,\n",
       " 'w_069c25b': 126,\n",
       " 'w_06a10b4': 127,\n",
       " 'w_06d2e72': 128,\n",
       " 'w_06de0a6': 129,\n",
       " 'w_06e4776': 130,\n",
       " 'w_06e6d5f': 131,\n",
       " 'w_06ec6e6': 132,\n",
       " 'w_06f3291': 133,\n",
       " 'w_06fb64a': 134,\n",
       " 'w_06ffb30': 135,\n",
       " 'w_070036a': 136,\n",
       " 'w_07019f4': 137,\n",
       " 'w_07125ed': 138,\n",
       " 'w_0714a46': 139,\n",
       " 'w_0717f05': 140,\n",
       " 'w_0718183': 141,\n",
       " 'w_072179d': 142,\n",
       " 'w_0729126': 143,\n",
       " 'w_072f593': 144,\n",
       " 'w_0741282': 145,\n",
       " 'w_074530d': 146,\n",
       " 'w_0745b0e': 147,\n",
       " 'w_0749e87': 148,\n",
       " 'w_074a5ba': 149,\n",
       " 'w_076bb5a': 150,\n",
       " 'w_07768b0': 151,\n",
       " 'w_0788c36': 152,\n",
       " 'w_07c946d': 153,\n",
       " 'w_07cb113': 154,\n",
       " 'w_07cc9c2': 155,\n",
       " 'w_07d4b0a': 156,\n",
       " 'w_07e0c3c': 157,\n",
       " 'w_08010cc': 158,\n",
       " 'w_0815d2c': 159,\n",
       " 'w_0823d50': 160,\n",
       " 'w_082978e': 161,\n",
       " 'w_082f603': 162,\n",
       " 'w_0833a92': 163,\n",
       " 'w_08630fd': 164,\n",
       " 'w_086f404': 165,\n",
       " 'w_08753b7': 166,\n",
       " 'w_0886321': 167,\n",
       " 'w_0887d9b': 168,\n",
       " 'w_0888e56': 169,\n",
       " 'w_088cda7': 170,\n",
       " 'w_08b0eac': 171,\n",
       " 'w_08c7d09': 172,\n",
       " 'w_08d439c': 173,\n",
       " 'w_08d5864': 174,\n",
       " 'w_08d62ee': 175,\n",
       " 'w_08eadf6': 176,\n",
       " 'w_090c08a': 177,\n",
       " 'w_090c801': 178,\n",
       " 'w_091ec23': 179,\n",
       " 'w_0926777': 180,\n",
       " 'w_092d942': 181,\n",
       " 'w_093d284': 182,\n",
       " 'w_093ea58': 183,\n",
       " 'w_095e3eb': 184,\n",
       " 'w_099bcbc': 185,\n",
       " 'w_09bd7e8': 186,\n",
       " 'w_09c59c2': 187,\n",
       " 'w_09c737d': 188,\n",
       " 'w_09c8a69': 189,\n",
       " 'w_09de1a5': 190,\n",
       " 'w_09e51f8': 191,\n",
       " 'w_0a0b4c6': 192,\n",
       " 'w_0a0c768': 193,\n",
       " 'w_0a155b9': 194,\n",
       " 'w_0a1fcd6': 195,\n",
       " 'w_0a2e1ef': 196,\n",
       " 'w_0a31a3a': 197,\n",
       " 'w_0a3255c': 198,\n",
       " 'w_0a357b7': 199,\n",
       " 'w_0a4f5c9': 200,\n",
       " 'w_0a619af': 201,\n",
       " 'w_0a6c4c7': 202,\n",
       " 'w_0a6e626': 203,\n",
       " 'w_0a7a37c': 204,\n",
       " 'w_0a84ac5': 205,\n",
       " 'w_0a87ea4': 206,\n",
       " 'w_0a8a451': 207,\n",
       " 'w_0a8d318': 208,\n",
       " 'w_0a8e080': 209,\n",
       " 'w_0abdaf4': 210,\n",
       " 'w_0abe9e7': 211,\n",
       " 'w_0ac10f3': 212,\n",
       " 'w_0ac1b5f': 213,\n",
       " 'w_0ad0f5b': 214,\n",
       " 'w_0ad1734': 215,\n",
       " 'w_0adb403': 216,\n",
       " 'w_0aea542': 217,\n",
       " 'w_0aed03f': 218,\n",
       " 'w_0af3867': 219,\n",
       " 'w_0b0168a': 220,\n",
       " 'w_0b10e7c': 221,\n",
       " 'w_0b1e4a6': 222,\n",
       " 'w_0b356c2': 223,\n",
       " 'w_0b398b2': 224,\n",
       " 'w_0b3e0e6': 225,\n",
       " 'w_0b4f7cf': 226,\n",
       " 'w_0b7ce1e': 227,\n",
       " 'w_0b995e5': 228,\n",
       " 'w_0b9cab4': 229,\n",
       " 'w_0baf946': 230,\n",
       " 'w_0bb71d3': 231,\n",
       " 'w_0bb9927': 232,\n",
       " 'w_0bbc3cb': 233,\n",
       " 'w_0bc078c': 234,\n",
       " 'w_0bc1de9': 235,\n",
       " 'w_0bd2e46': 236,\n",
       " 'w_0bd39c1': 237,\n",
       " 'w_0bdb7a5': 238,\n",
       " 'w_0bdc5d5': 239,\n",
       " 'w_0bf90d9': 240,\n",
       " 'w_0bfc890': 241,\n",
       " 'w_0bfdcca': 242,\n",
       " 'w_0c23936': 243,\n",
       " 'w_0c59853': 244,\n",
       " 'w_0c5f019': 245,\n",
       " 'w_0c69117': 246,\n",
       " 'w_0c76541': 247,\n",
       " 'w_0c76e03': 248,\n",
       " 'w_0c7ab0d': 249,\n",
       " 'w_0c80c53': 250,\n",
       " 'w_0ca546b': 251,\n",
       " 'w_0cadbdc': 252,\n",
       " 'w_0cbf1b3': 253,\n",
       " 'w_0cc0430': 254,\n",
       " 'w_0cdca97': 255,\n",
       " 'w_0ce0555': 256,\n",
       " 'w_0ce537a': 257,\n",
       " 'w_0cfae04': 258,\n",
       " 'w_0cfdaa5': 259,\n",
       " 'w_0d052c1': 260,\n",
       " 'w_0d11fa9': 261,\n",
       " 'w_0d145d4': 262,\n",
       " 'w_0d1b964': 263,\n",
       " 'w_0d43823': 264,\n",
       " 'w_0d4a14b': 265,\n",
       " 'w_0d54c55': 266,\n",
       " 'w_0d5a672': 267,\n",
       " 'w_0d5fa2c': 268,\n",
       " 'w_0d61101': 269,\n",
       " 'w_0d77f32': 270,\n",
       " 'w_0d7b050': 271,\n",
       " 'w_0d93517': 272,\n",
       " 'w_0d98e43': 273,\n",
       " 'w_0d9ddce': 274,\n",
       " 'w_0da34d3': 275,\n",
       " 'w_0da9a8f': 276,\n",
       " 'w_0db234e': 277,\n",
       " 'w_0db2e26': 278,\n",
       " 'w_0dc84fd': 279,\n",
       " 'w_0dd4a5d': 280,\n",
       " 'w_0df7caf': 281,\n",
       " 'w_0dfb4f6': 282,\n",
       " 'w_0dfc1eb': 283,\n",
       " 'w_0e0b65c': 284,\n",
       " 'w_0e0f074': 285,\n",
       " 'w_0e1eccb': 286,\n",
       " 'w_0e26d1a': 287,\n",
       " 'w_0e2a5bd': 288,\n",
       " 'w_0e2b483': 289,\n",
       " 'w_0e325b0': 290,\n",
       " 'w_0e34e76': 291,\n",
       " 'w_0e35358': 292,\n",
       " 'w_0e4b65e': 293,\n",
       " 'w_0e7aae1': 294,\n",
       " 'w_0e7ec27': 295,\n",
       " 'w_0e8341d': 296,\n",
       " 'w_0e93f25': 297,\n",
       " 'w_0e9f07a': 298,\n",
       " 'w_0ea7436': 299,\n",
       " 'w_0eab54f': 300,\n",
       " 'w_0ecda0a': 301,\n",
       " 'w_0ee1b0f': 302,\n",
       " 'w_0ee7878': 303,\n",
       " 'w_0ee9ae5': 304,\n",
       " 'w_0ef790d': 305,\n",
       " 'w_0f00df0': 306,\n",
       " 'w_0f031ca': 307,\n",
       " 'w_0f03c44': 308,\n",
       " 'w_0f0f15c': 309,\n",
       " 'w_0f1cf57': 310,\n",
       " 'w_0f25e3c': 311,\n",
       " 'w_0f25e6b': 312,\n",
       " 'w_0f466a5': 313,\n",
       " 'w_0f4d4ac': 314,\n",
       " 'w_0f5666b': 315,\n",
       " 'w_0f56fb2': 316,\n",
       " 'w_0f5d895': 317,\n",
       " 'w_0f73f48': 318,\n",
       " 'w_0f84e7c': 319,\n",
       " 'w_0f86e70': 320,\n",
       " 'w_0f8ab07': 321,\n",
       " 'w_0f8b8e2': 322,\n",
       " 'w_0fb38fe': 323,\n",
       " 'w_0fc3e41': 324,\n",
       " 'w_0fdde23': 325,\n",
       " 'w_0fdf741': 326,\n",
       " 'w_0fe07b7': 327,\n",
       " 'w_0fe6fbb': 328,\n",
       " 'w_0fedd59': 329,\n",
       " 'w_0fefc62': 330,\n",
       " 'w_0ffa15f': 331,\n",
       " 'w_1006b9c': 332,\n",
       " 'w_101990d': 333,\n",
       " 'w_102821e': 334,\n",
       " 'w_1029215': 335,\n",
       " 'w_102e715': 336,\n",
       " 'w_1032bb6': 337,\n",
       " 'w_1032fa3': 338,\n",
       " 'w_103aca2': 339,\n",
       " 'w_104d305': 340,\n",
       " 'w_105b860': 341,\n",
       " 'w_107b98e': 342,\n",
       " 'w_1082fdc': 343,\n",
       " 'w_1083a05': 344,\n",
       " 'w_108b2ed': 345,\n",
       " 'w_10a4e10': 346,\n",
       " 'w_10b4603': 347,\n",
       " 'w_10bb1ba': 348,\n",
       " 'w_10d9667': 349,\n",
       " 'w_10eece8': 350,\n",
       " 'w_10f3b75': 351,\n",
       " 'w_10f4afc': 352,\n",
       " 'w_10f67bb': 353,\n",
       " 'w_1104cca': 354,\n",
       " 'w_1106cbb': 355,\n",
       " 'w_112d2f8': 356,\n",
       " 'w_1133530': 357,\n",
       " 'w_114a297': 358,\n",
       " 'w_115e880': 359,\n",
       " 'w_1167daf': 360,\n",
       " 'w_118a4a4': 361,\n",
       " 'w_118fad5': 362,\n",
       " 'w_119f570': 363,\n",
       " 'w_11ac036': 364,\n",
       " 'w_11bd416': 365,\n",
       " 'w_11ce746': 366,\n",
       " 'w_11d8c70': 367,\n",
       " 'w_11e75bf': 368,\n",
       " 'w_11e90bc': 369,\n",
       " 'w_11ec829': 370,\n",
       " 'w_11ff425': 371,\n",
       " 'w_1217536': 372,\n",
       " 'w_1220336': 373,\n",
       " 'w_122e247': 374,\n",
       " 'w_122eec1': 375,\n",
       " 'w_1247b8c': 376,\n",
       " 'w_124a3cb': 377,\n",
       " 'w_1257748': 378,\n",
       " 'w_1260eb5': 379,\n",
       " 'w_1275240': 380,\n",
       " 'w_1286f9e': 381,\n",
       " 'w_1289b63': 382,\n",
       " 'w_12aae3e': 383,\n",
       " 'w_12b56df': 384,\n",
       " 'w_12cc52d': 385,\n",
       " 'w_12ce4f8': 386,\n",
       " 'w_12e7c23': 387,\n",
       " 'w_12e8dc7': 388,\n",
       " 'w_12fdac7': 389,\n",
       " 'w_12fe3a8': 390,\n",
       " 'w_13250ab': 391,\n",
       " 'w_1344da3': 392,\n",
       " 'w_13937e4': 393,\n",
       " 'w_139d19a': 394,\n",
       " 'w_13a7d9a': 395,\n",
       " 'w_13aa123': 396,\n",
       " 'w_13ae3d4': 397,\n",
       " 'w_13b343c': 398,\n",
       " 'w_13c1b55': 399,\n",
       " 'w_13c715a': 400,\n",
       " 'w_13c8177': 401,\n",
       " 'w_13c9277': 402,\n",
       " 'w_13c9a17': 403,\n",
       " 'w_13ca7e8': 404,\n",
       " 'w_13d4fd0': 405,\n",
       " 'w_13e8097': 406,\n",
       " 'w_13edc47': 407,\n",
       " 'w_13ffdcf': 408,\n",
       " 'w_1403973': 409,\n",
       " 'w_140a9ac': 410,\n",
       " 'w_1417bc8': 411,\n",
       " 'w_1419d90': 412,\n",
       " 'w_141a880': 413,\n",
       " 'w_1423c1f': 414,\n",
       " 'w_14330a0': 415,\n",
       " 'w_143ea92': 416,\n",
       " 'w_14461a7': 417,\n",
       " 'w_144ecb6': 418,\n",
       " 'w_1457f13': 419,\n",
       " 'w_146208a': 420,\n",
       " 'w_1472271': 421,\n",
       " 'w_1483be2': 422,\n",
       " 'w_148921b': 423,\n",
       " 'w_14a74dd': 424,\n",
       " 'w_14b1427': 425,\n",
       " 'w_14bfbe2': 426,\n",
       " 'w_14e1334': 427,\n",
       " 'w_14e5fe2': 428,\n",
       " 'w_14ece76': 429,\n",
       " 'w_14f15a0': 430,\n",
       " 'w_150a6f5': 431,\n",
       " 'w_1531bf5': 432,\n",
       " 'w_1554173': 433,\n",
       " 'w_1574bd1': 434,\n",
       " 'w_1579152': 435,\n",
       " 'w_15805cd': 436,\n",
       " 'w_15951db': 437,\n",
       " 'w_15a9ec1': 438,\n",
       " 'w_15b3f09': 439,\n",
       " 'w_15b5df2': 440,\n",
       " 'w_15b5eb1': 441,\n",
       " 'w_15bf3e3': 442,\n",
       " 'w_15bf4be': 443,\n",
       " 'w_15d12c7': 444,\n",
       " 'w_15e3099': 445,\n",
       " 'w_15e7de5': 446,\n",
       " 'w_15f43ea': 447,\n",
       " 'w_15fb899': 448,\n",
       " 'w_1632c45': 449,\n",
       " 'w_16362a6': 450,\n",
       " 'w_163b2b8': 451,\n",
       " 'w_1647882': 452,\n",
       " 'w_1650208': 453,\n",
       " 'w_1666216': 454,\n",
       " 'w_167a348': 455,\n",
       " 'w_1684cac': 456,\n",
       " 'w_169253a': 457,\n",
       " 'w_1693b27': 458,\n",
       " 'w_169a302': 459,\n",
       " 'w_16a13bb': 460,\n",
       " 'w_16b5050': 461,\n",
       " 'w_16b7fec': 462,\n",
       " 'w_16c264e': 463,\n",
       " 'w_16dba74': 464,\n",
       " 'w_16def42': 465,\n",
       " 'w_16df050': 466,\n",
       " 'w_16dfac7': 467,\n",
       " 'w_16f4e1e': 468,\n",
       " 'w_16fa149': 469,\n",
       " 'w_171794e': 470,\n",
       " 'w_1719d81': 471,\n",
       " 'w_171ca39': 472,\n",
       " 'w_171dc55': 473,\n",
       " 'w_1728040': 474,\n",
       " 'w_17338da': 475,\n",
       " 'w_1759e4e': 476,\n",
       " 'w_175d6fa': 477,\n",
       " 'w_177d88e': 478,\n",
       " 'w_178144f': 479,\n",
       " 'w_1788910': 480,\n",
       " 'w_179c9f0': 481,\n",
       " 'w_17a108a': 482,\n",
       " 'w_17a3a21': 483,\n",
       " 'w_17a4a41': 484,\n",
       " 'w_17b0d3a': 485,\n",
       " 'w_17ba5e4': 486,\n",
       " 'w_17be6f2': 487,\n",
       " 'w_17c9df5': 488,\n",
       " 'w_17d6235': 489,\n",
       " 'w_17dd986': 490,\n",
       " 'w_17e8846': 491,\n",
       " 'w_17f5d1d': 492,\n",
       " 'w_17fef9b': 493,\n",
       " 'w_180e241': 494,\n",
       " 'w_181ab06': 495,\n",
       " 'w_1834b49': 496,\n",
       " 'w_185044d': 497,\n",
       " 'w_185bc11': 498,\n",
       " 'w_18645ff': 499,\n",
       " 'w_18666da': 500,\n",
       " 'w_186d294': 501,\n",
       " 'w_1870783': 502,\n",
       " 'w_187de67': 503,\n",
       " 'w_1887b5a': 504,\n",
       " 'w_18934ab': 505,\n",
       " 'w_18a06fd': 506,\n",
       " 'w_18aafe8': 507,\n",
       " 'w_18c481a': 508,\n",
       " 'w_18ca0f1': 509,\n",
       " 'w_18f9d19': 510,\n",
       " 'w_190375b': 511,\n",
       " 'w_190b9bb': 512,\n",
       " 'w_191bce3': 513,\n",
       " 'w_1920193': 514,\n",
       " 'w_1930599': 515,\n",
       " 'w_1932830': 516,\n",
       " 'w_193bf22': 517,\n",
       " 'w_193f83c': 518,\n",
       " 'w_19410fe': 519,\n",
       " 'w_194bea2': 520,\n",
       " 'w_19671ad': 521,\n",
       " 'w_197979e': 522,\n",
       " 'w_1995d15': 523,\n",
       " 'w_19a0b30': 524,\n",
       " 'w_19bd11d': 525,\n",
       " 'w_19c50fa': 526,\n",
       " 'w_19dfa67': 527,\n",
       " 'w_19f365e': 528,\n",
       " 'w_19f507e': 529,\n",
       " 'w_19fb122': 530,\n",
       " 'w_1a071a3': 531,\n",
       " 'w_1a151e5': 532,\n",
       " 'w_1a20162': 533,\n",
       " 'w_1a31542': 534,\n",
       " 'w_1a619db': 535,\n",
       " 'w_1a657fc': 536,\n",
       " 'w_1a70f3a': 537,\n",
       " 'w_1a7ccaf': 538,\n",
       " 'w_1a874a6': 539,\n",
       " 'w_1a96d7b': 540,\n",
       " 'w_1a9e018': 541,\n",
       " 'w_1ab568f': 542,\n",
       " 'w_1af6b9a': 543,\n",
       " 'w_1afed1e': 544,\n",
       " 'w_1afff3f': 545,\n",
       " 'w_1b00c27': 546,\n",
       " 'w_1b04c3c': 547,\n",
       " 'w_1b0c4b7': 548,\n",
       " 'w_1b0db58': 549,\n",
       " 'w_1b1dd05': 550,\n",
       " 'w_1b2bf0f': 551,\n",
       " 'w_1b3baf7': 552,\n",
       " 'w_1b3c3a4': 553,\n",
       " 'w_1b4b202': 554,\n",
       " 'w_1b4bb29': 555,\n",
       " 'w_1b50676': 556,\n",
       " 'w_1b51678': 557,\n",
       " 'w_1b5b199': 558,\n",
       " 'w_1b5fd1b': 559,\n",
       " 'w_1b6f30f': 560,\n",
       " 'w_1b6f6dc': 561,\n",
       " 'w_1b70bda': 562,\n",
       " 'w_1b70f3f': 563,\n",
       " 'w_1b77e4f': 564,\n",
       " 'w_1b7eaad': 565,\n",
       " 'w_1b8f126': 566,\n",
       " 'w_1baf8df': 567,\n",
       " 'w_1bbc982': 568,\n",
       " 'w_1bd2d91': 569,\n",
       " 'w_1be76f5': 570,\n",
       " 'w_1c2e409': 571,\n",
       " 'w_1c39fb1': 572,\n",
       " 'w_1c47899': 573,\n",
       " 'w_1c55cc3': 574,\n",
       " 'w_1c63738': 575,\n",
       " 'w_1c6465a': 576,\n",
       " 'w_1ca7433': 577,\n",
       " 'w_1ca9ab1': 578,\n",
       " 'w_1cb0ffc': 579,\n",
       " 'w_1ccd2a1': 580,\n",
       " 'w_1ccea93': 581,\n",
       " 'w_1cfebce': 582,\n",
       " 'w_1d0830e': 583,\n",
       " 'w_1d1fffe': 584,\n",
       " 'w_1d2d323': 585,\n",
       " 'w_1d2ed91': 586,\n",
       " 'w_1d35a02': 587,\n",
       " 'w_1d4e949': 588,\n",
       " 'w_1d532b4': 589,\n",
       " 'w_1d55e83': 590,\n",
       " 'w_1d6a51b': 591,\n",
       " 'w_1d6a9f7': 592,\n",
       " 'w_1d7fd7d': 593,\n",
       " 'w_1d830c2': 594,\n",
       " 'w_1d8d7c3': 595,\n",
       " 'w_1d9592f': 596,\n",
       " 'w_1da3327': 597,\n",
       " 'w_1da93f8': 598,\n",
       " 'w_1daae48': 599,\n",
       " 'w_1dc7d3a': 600,\n",
       " 'w_1dd336a': 601,\n",
       " 'w_1de6148': 602,\n",
       " 'w_1df2383': 603,\n",
       " 'w_1dff836': 604,\n",
       " 'w_1e1e5d9': 605,\n",
       " 'w_1e283bb': 606,\n",
       " 'w_1e286e0': 607,\n",
       " 'w_1e3b8e8': 608,\n",
       " 'w_1e3caae': 609,\n",
       " 'w_1e3e9a7': 610,\n",
       " 'w_1e81b43': 611,\n",
       " 'w_1e85eea': 612,\n",
       " 'w_1e99233': 613,\n",
       " 'w_1e9caad': 614,\n",
       " 'w_1ea5d96': 615,\n",
       " 'w_1ea8997': 616,\n",
       " 'w_1eb67e3': 617,\n",
       " 'w_1ebcda9': 618,\n",
       " 'w_1ecca2d': 619,\n",
       " 'w_1ee38d5': 620,\n",
       " 'w_1ef6c12': 621,\n",
       " 'w_1efb6fa': 622,\n",
       " 'w_1efbb8e': 623,\n",
       " 'w_1f0cf0a': 624,\n",
       " 'w_1f1774e': 625,\n",
       " 'w_1f1cee1': 626,\n",
       " 'w_1f41b98': 627,\n",
       " 'w_1f429ff': 628,\n",
       " 'w_1f62b56': 629,\n",
       " 'w_1f6de0b': 630,\n",
       " 'w_1f78a1e': 631,\n",
       " 'w_1f7c696': 632,\n",
       " 'w_1f7e291': 633,\n",
       " 'w_1f85037': 634,\n",
       " 'w_1f8621d': 635,\n",
       " 'w_1f8c439': 636,\n",
       " 'w_1faaf06': 637,\n",
       " 'w_1faf1e4': 638,\n",
       " 'w_1fb652d': 639,\n",
       " 'w_1fc42e2': 640,\n",
       " 'w_1fc4625': 641,\n",
       " 'w_1fe6c6e': 642,\n",
       " 'w_1fecb34': 643,\n",
       " 'w_1ff111d': 644,\n",
       " 'w_1ff1582': 645,\n",
       " 'w_1ff168e': 646,\n",
       " 'w_1ff410a': 647,\n",
       " 'w_1ffc4ab': 648,\n",
       " 'w_2009f8b': 649,\n",
       " 'w_203042e': 650,\n",
       " 'w_2034344': 651,\n",
       " 'w_2036a57': 652,\n",
       " 'w_205708f': 653,\n",
       " 'w_2059146': 654,\n",
       " 'w_207f153': 655,\n",
       " 'w_208db25': 656,\n",
       " 'w_20930e7': 657,\n",
       " 'w_20950a9': 658,\n",
       " 'w_20ad973': 659,\n",
       " 'w_20baeef': 660,\n",
       " 'w_20c0bc0': 661,\n",
       " 'w_20df2c5': 662,\n",
       " 'w_20dfb69': 663,\n",
       " 'w_20edfc3': 664,\n",
       " 'w_20eeb29': 665,\n",
       " 'w_2103ca8': 666,\n",
       " 'w_210b625': 667,\n",
       " 'w_210caac': 668,\n",
       " 'w_2112103': 669,\n",
       " 'w_2117e10': 670,\n",
       " 'w_2136d08': 671,\n",
       " 'w_2137c6f': 672,\n",
       " 'w_213fb07': 673,\n",
       " 'w_2148753': 674,\n",
       " 'w_214e081': 675,\n",
       " 'w_21591ba': 676,\n",
       " 'w_21666ad': 677,\n",
       " 'w_217fc01': 678,\n",
       " 'w_218fe4a': 679,\n",
       " 'w_21a7dac': 680,\n",
       " 'w_21ae2d7': 681,\n",
       " 'w_21b2790': 682,\n",
       " 'w_21b3c7e': 683,\n",
       " 'w_21b94e3': 684,\n",
       " 'w_21bb5bd': 685,\n",
       " 'w_21d5943': 686,\n",
       " 'w_21ecbf3': 687,\n",
       " 'w_21f1129': 688,\n",
       " 'w_21fd105': 689,\n",
       " 'w_2211e6d': 690,\n",
       " 'w_222ba28': 691,\n",
       " 'w_224bfc5': 692,\n",
       " 'w_227e394': 693,\n",
       " 'w_2284d86': 694,\n",
       " 'w_228c7ee': 695,\n",
       " 'w_2296421': 696,\n",
       " 'w_22a168a': 697,\n",
       " 'w_22b8752': 698,\n",
       " 'w_22cdc5f': 699,\n",
       " 'w_22d96e7': 700,\n",
       " 'w_22e82fa': 701,\n",
       " 'w_22f2567': 702,\n",
       " 'w_22f46ab': 703,\n",
       " 'w_232f528': 704,\n",
       " 'w_2330989': 705,\n",
       " 'w_234713b': 706,\n",
       " 'w_2349681': 707,\n",
       " 'w_234d686': 708,\n",
       " 'w_2362d7f': 709,\n",
       " 'w_2365d55': 710,\n",
       " 'w_23852a0': 711,\n",
       " 'w_23a388d': 712,\n",
       " 'w_23bfd0a': 713,\n",
       " 'w_23ce00e': 714,\n",
       " 'w_23d4815': 715,\n",
       " 'w_23e1d57': 716,\n",
       " 'w_24076b5': 717,\n",
       " 'w_2409871': 718,\n",
       " 'w_240cbf9': 719,\n",
       " 'w_2424e82': 720,\n",
       " 'w_242fb46': 721,\n",
       " 'w_243b654': 722,\n",
       " 'w_244ab03': 723,\n",
       " 'w_244e953': 724,\n",
       " 'w_245ac74': 725,\n",
       " 'w_248381e': 726,\n",
       " 'w_249346b': 727,\n",
       " 'w_2495755': 728,\n",
       " 'w_2497490': 729,\n",
       " 'w_24b2561': 730,\n",
       " 'w_24b5070': 731,\n",
       " 'w_24c6ff8': 732,\n",
       " 'w_24c76d8': 733,\n",
       " 'w_24ca106': 734,\n",
       " 'w_24d3109': 735,\n",
       " 'w_24e9b5d': 736,\n",
       " 'w_2500327': 737,\n",
       " 'w_25085e0': 738,\n",
       " 'w_25183b8': 739,\n",
       " 'w_252d315': 740,\n",
       " 'w_2548d54': 741,\n",
       " 'w_2570b49': 742,\n",
       " 'w_257e223': 743,\n",
       " 'w_2592960': 744,\n",
       " 'w_2597710': 745,\n",
       " 'w_25b2b3d': 746,\n",
       " 'w_25d662d': 747,\n",
       " 'w_25d7e08': 748,\n",
       " 'w_25e04d9': 749,\n",
       " 'w_25f1a4e': 750,\n",
       " 'w_260a2e7': 751,\n",
       " 'w_260b2ac': 752,\n",
       " 'w_260e1d7': 753,\n",
       " 'w_260ff2c': 754,\n",
       " 'w_261878d': 755,\n",
       " 'w_2623921': 756,\n",
       " 'w_2623b69': 757,\n",
       " 'w_262c32f': 758,\n",
       " 'w_262ec5b': 759,\n",
       " 'w_26301f8': 760,\n",
       " 'w_263bd97': 761,\n",
       " 'w_263fcb0': 762,\n",
       " 'w_2644b11': 763,\n",
       " 'w_2645f4d': 764,\n",
       " 'w_264c2e1': 765,\n",
       " 'w_2652d72': 766,\n",
       " 'w_265ac62': 767,\n",
       " 'w_267c7e3': 768,\n",
       " 'w_268addf': 769,\n",
       " 'w_26923f7': 770,\n",
       " 'w_2694603': 771,\n",
       " 'w_26a55ed': 772,\n",
       " 'w_26aeb61': 773,\n",
       " 'w_26b24d4': 774,\n",
       " 'w_26ba5fd': 775,\n",
       " 'w_26c0ffd': 776,\n",
       " 'w_26db444': 777,\n",
       " 'w_26e4f44': 778,\n",
       " 'w_26f7c39': 779,\n",
       " 'w_270f505': 780,\n",
       " 'w_2719f85': 781,\n",
       " 'w_27272a5': 782,\n",
       " 'w_274397d': 783,\n",
       " 'w_2745292': 784,\n",
       " 'w_274d994': 785,\n",
       " 'w_274f6db': 786,\n",
       " 'w_2757c07': 787,\n",
       " 'w_27597ff': 788,\n",
       " 'w_2759bb6': 789,\n",
       " 'w_276390d': 790,\n",
       " 'w_276d61d': 791,\n",
       " 'w_277d911': 792,\n",
       " 'w_27a6304': 793,\n",
       " 'w_27aa28c': 794,\n",
       " 'w_27b7295': 795,\n",
       " 'w_27be996': 796,\n",
       " 'w_27d6aac': 797,\n",
       " 'w_27fa393': 798,\n",
       " 'w_27fd7e3': 799,\n",
       " 'w_2807565': 800,\n",
       " 'w_2812e0d': 801,\n",
       " 'w_281a8cd': 802,\n",
       " 'w_28218e1': 803,\n",
       " 'w_283ceeb': 804,\n",
       " 'w_2843a30': 805,\n",
       " 'w_2852461': 806,\n",
       " 'w_2856c57': 807,\n",
       " 'w_28589bc': 808,\n",
       " 'w_2858e46': 809,\n",
       " 'w_286d2cc': 810,\n",
       " 'w_289778b': 811,\n",
       " 'w_28a16b0': 812,\n",
       " 'w_28c1ced': 813,\n",
       " 'w_28c330c': 814,\n",
       " 'w_28cb717': 815,\n",
       " 'w_28d57ec': 816,\n",
       " 'w_28df1bb': 817,\n",
       " 'w_28f572d': 818,\n",
       " 'w_2902e69': 819,\n",
       " 'w_290399a': 820,\n",
       " 'w_291b418': 821,\n",
       " 'w_291cba5': 822,\n",
       " 'w_2926c77': 823,\n",
       " 'w_292956e': 824,\n",
       " 'w_293431f': 825,\n",
       " 'w_2964e0b': 826,\n",
       " 'w_2972f31': 827,\n",
       " 'w_297503e': 828,\n",
       " 'w_297e53a': 829,\n",
       " 'w_2980f85': 830,\n",
       " 'w_298a035': 831,\n",
       " 'w_298f605': 832,\n",
       " 'w_29a8580': 833,\n",
       " 'w_29af733': 834,\n",
       " 'w_29c0caf': 835,\n",
       " 'w_29c88c2': 836,\n",
       " 'w_29cde7c': 837,\n",
       " 'w_29d806a': 838,\n",
       " 'w_29e5e8e': 839,\n",
       " 'w_29e8496': 840,\n",
       " 'w_29e87c9': 841,\n",
       " 'w_2a0e817': 842,\n",
       " 'w_2a1a012': 843,\n",
       " 'w_2a1a125': 844,\n",
       " 'w_2a2bcf1': 845,\n",
       " 'w_2a6d5ee': 846,\n",
       " 'w_2a7603f': 847,\n",
       " 'w_2a7c1af': 848,\n",
       " 'w_2a7f00f': 849,\n",
       " 'w_2a946f2': 850,\n",
       " 'w_2a98962': 851,\n",
       " 'w_2aaa3b5': 852,\n",
       " 'w_2ab34d0': 853,\n",
       " 'w_2ac2bac': 854,\n",
       " 'w_2ac6611': 855,\n",
       " 'w_2ad05e9': 856,\n",
       " 'w_2ae40f9': 857,\n",
       " 'w_2af46a8': 858,\n",
       " 'w_2b069ba': 859,\n",
       " 'w_2b17316': 860,\n",
       " 'w_2b1b04e': 861,\n",
       " 'w_2b388fe': 862,\n",
       " 'w_2b39f31': 863,\n",
       " 'w_2b47174': 864,\n",
       " 'w_2b49489': 865,\n",
       " 'w_2b4b82e': 866,\n",
       " 'w_2b50adf': 867,\n",
       " 'w_2b65b34': 868,\n",
       " 'w_2b7f65a': 869,\n",
       " 'w_2b979e6': 870,\n",
       " 'w_2ba6978': 871,\n",
       " 'w_2c0cfe8': 872,\n",
       " 'w_2c0f96c': 873,\n",
       " 'w_2c1a562': 874,\n",
       " 'w_2c29146': 875,\n",
       " 'w_2c2e6b9': 876,\n",
       " 'w_2c3768d': 877,\n",
       " 'w_2c3c217': 878,\n",
       " 'w_2c3f556': 879,\n",
       " 'w_2c5fe7e': 880,\n",
       " 'w_2c7deff': 881,\n",
       " 'w_2c94198': 882,\n",
       " 'w_2ca9282': 883,\n",
       " 'w_2cabd62': 884,\n",
       " 'w_2cd7341': 885,\n",
       " 'w_2cdde18': 886,\n",
       " 'w_2d0cfc1': 887,\n",
       " 'w_2d1592c': 888,\n",
       " 'w_2d1d67a': 889,\n",
       " 'w_2d3ef19': 890,\n",
       " 'w_2d5492b': 891,\n",
       " 'w_2d5b0e1': 892,\n",
       " 'w_2d5dc31': 893,\n",
       " 'w_2d6596f': 894,\n",
       " 'w_2d6bb89': 895,\n",
       " 'w_2d7c2dd': 896,\n",
       " 'w_2d99567': 897,\n",
       " 'w_2db0644': 898,\n",
       " 'w_2dd6b62': 899,\n",
       " 'w_2ddcce9': 900,\n",
       " 'w_2de1c5c': 901,\n",
       " 'w_2df1d85': 902,\n",
       " 'w_2df37cc': 903,\n",
       " 'w_2df85e7': 904,\n",
       " 'w_2e075b2': 905,\n",
       " 'w_2e1416e': 906,\n",
       " 'w_2e18226': 907,\n",
       " 'w_2e21094': 908,\n",
       " 'w_2e231f4': 909,\n",
       " 'w_2e29743': 910,\n",
       " 'w_2e35d7c': 911,\n",
       " 'w_2e374c0': 912,\n",
       " 'w_2e3e30d': 913,\n",
       " 'w_2e45865': 914,\n",
       " 'w_2e4af64': 915,\n",
       " 'w_2e4b740': 916,\n",
       " 'w_2e4cb98': 917,\n",
       " 'w_2e54183': 918,\n",
       " 'w_2e5ad54': 919,\n",
       " 'w_2e5d992': 920,\n",
       " 'w_2e69752': 921,\n",
       " 'w_2e706fc': 922,\n",
       " 'w_2e9d1b5': 923,\n",
       " 'w_2e9ed59': 924,\n",
       " 'w_2ec0a71': 925,\n",
       " 'w_2ed0acc': 926,\n",
       " 'w_2ed0d2f': 927,\n",
       " 'w_2ed1e39': 928,\n",
       " 'w_2eec458': 929,\n",
       " 'w_2ef6741': 930,\n",
       " 'w_2ef9c36': 931,\n",
       " 'w_2efa6ab': 932,\n",
       " 'w_2f0416b': 933,\n",
       " 'w_2f0f74c': 934,\n",
       " 'w_2f1488c': 935,\n",
       " 'w_2f2c0d6': 936,\n",
       " 'w_2f350be': 937,\n",
       " 'w_2f3badb': 938,\n",
       " 'w_2f4be30': 939,\n",
       " 'w_2f5652a': 940,\n",
       " 'w_2f5caa9': 941,\n",
       " 'w_2f67f0a': 942,\n",
       " 'w_2f6d4a8': 943,\n",
       " 'w_2f702db': 944,\n",
       " 'w_2f74ff3': 945,\n",
       " 'w_2f79ae3': 946,\n",
       " 'w_2f841ea': 947,\n",
       " 'w_2f87cc7': 948,\n",
       " 'w_2f8895a': 949,\n",
       " 'w_2f8de4f': 950,\n",
       " 'w_2f8eda5': 951,\n",
       " 'w_2f94559': 952,\n",
       " 'w_2f9b02c': 953,\n",
       " 'w_2fc317c': 954,\n",
       " 'w_2fc775e': 955,\n",
       " 'w_2fcfc71': 956,\n",
       " 'w_2fdb049': 957,\n",
       " 'w_2fdf4cb': 958,\n",
       " 'w_2fe1c3f': 959,\n",
       " 'w_2fec5ea': 960,\n",
       " 'w_2ff0834': 961,\n",
       " 'w_3002b59': 962,\n",
       " 'w_301f728': 963,\n",
       " 'w_302799d': 964,\n",
       " 'w_303a3c4': 965,\n",
       " 'w_3040ecd': 966,\n",
       " 'w_305456a': 967,\n",
       " 'w_3057209': 968,\n",
       " 'w_3067220': 969,\n",
       " 'w_30719c8': 970,\n",
       " 'w_3079e26': 971,\n",
       " 'w_307e5e9': 972,\n",
       " 'w_308c7b6': 973,\n",
       " 'w_30a7b3f': 974,\n",
       " 'w_30b577d': 975,\n",
       " 'w_30f2f0f': 976,\n",
       " 'w_310226c': 977,\n",
       " 'w_3108dce': 978,\n",
       " 'w_310a26b': 979,\n",
       " 'w_310a94d': 980,\n",
       " 'w_31154fa': 981,\n",
       " 'w_31233f8': 982,\n",
       " 'w_3128adb': 983,\n",
       " 'w_3132fce': 984,\n",
       " 'w_3137898': 985,\n",
       " 'w_3137deb': 986,\n",
       " 'w_31438a5': 987,\n",
       " 'w_314bc30': 988,\n",
       " 'w_3154c82': 989,\n",
       " 'w_3155d04': 990,\n",
       " 'w_315c854': 991,\n",
       " 'w_317ae6c': 992,\n",
       " 'w_317c071': 993,\n",
       " 'w_3180b48': 994,\n",
       " 'w_31b5dd8': 995,\n",
       " 'w_31d1d50': 996,\n",
       " 'w_31e1bc1': 997,\n",
       " 'w_32015c2': 998,\n",
       " 'w_32043b0': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allimg.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45b15d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:04.156435Z",
     "iopub.status.busy": "2022-03-19T22:42:04.155879Z",
     "iopub.status.idle": "2022-03-19T22:42:08.895057Z",
     "shell.execute_reply": "2022-03-19T22:42:08.894619Z",
     "shell.execute_reply.started": "2022-03-19T22:32:00.001453Z"
    },
    "papermill": {
     "duration": 4.772939,
     "end_time": "2022-03-19T22:42:08.895180",
     "exception": false,
     "start_time": "2022-03-19T22:42:04.122241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnext50_32x4d_a1h-0146ab0a.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d_a1h-0146ab0a.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomResNext(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=2048, out_features=5005, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = CustomResNext('resnext50_32x4d', len(allimg.class_to_idx.keys()))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddabe888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:09.288085Z",
     "iopub.status.busy": "2022-03-19T22:42:09.278907Z",
     "iopub.status.idle": "2022-03-19T22:42:09.291545Z",
     "shell.execute_reply": "2022-03-19T22:42:09.291997Z",
     "shell.execute_reply.started": "2022-03-19T22:32:08.214017Z"
    },
    "papermill": {
     "duration": 0.076041,
     "end_time": "2022-03-19T22:42:09.292164",
     "exception": false,
     "start_time": "2022-03-19T22:42:09.216123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module): \n",
    "    def __init__(self, classes=5, smoothing=0.0, dim=-1): \n",
    "        super(LabelSmoothingLoss, self).__init__() \n",
    "        self.confidence = 1.0 - smoothing \n",
    "        self.smoothing = smoothing \n",
    "        self.cls = classes \n",
    "        self.dim = dim \n",
    "    def forward(self, pred, target): \n",
    "        pred = pred.log_softmax(dim=self.dim) \n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred) \n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "        \n",
    "class TaylorSoftmax(nn.Module):\n",
    "    '''\n",
    "    This is the autograd version\n",
    "    '''\n",
    "    def __init__(self, dim=1, n=2):\n",
    "        super(TaylorSoftmax, self).__init__()\n",
    "        assert n % 2 == 0\n",
    "        self.dim = dim\n",
    "        self.n = n\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        usage similar to nn.Softmax:\n",
    "            >>> mod = TaylorSoftmax(dim=1, n=4)\n",
    "            >>> inten = torch.randn(1, 32, 64, 64)\n",
    "            >>> out = mod(inten)\n",
    "        '''\n",
    "        fn = torch.ones_like(x)\n",
    "        denor = 1.\n",
    "        for i in range(1, self.n+1):\n",
    "            denor *= i\n",
    "            fn = fn + x.pow(i) / denor\n",
    "        out = fn / fn.sum(dim=self.dim, keepdims=True)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f5e5d02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:09.445819Z",
     "iopub.status.busy": "2022-03-19T22:42:09.445059Z",
     "iopub.status.idle": "2022-03-19T22:42:20.794537Z",
     "shell.execute_reply": "2022-03-19T22:42:20.793424Z",
     "shell.execute_reply.started": "2022-03-19T22:32:08.23213Z"
    },
    "papermill": {
     "duration": 11.415668,
     "end_time": "2022-03-19T22:42:20.794701",
     "exception": false,
     "start_time": "2022-03-19T22:42:09.379033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none -q https://github.com/ildoonet/pytorch-gradual-warmup-lr.git /tmp/pip-req-build-_fs8i6k6\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git > lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf112af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:20.862368Z",
     "iopub.status.busy": "2022-03-19T22:42:20.861464Z",
     "iopub.status.idle": "2022-03-19T22:42:20.873579Z",
     "shell.execute_reply": "2022-03-19T22:42:20.874003Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.601313Z"
    },
    "papermill": {
     "duration": 0.04644,
     "end_time": "2022-03-19T22:42:20.874151",
     "exception": false,
     "start_time": "2022-03-19T22:42:20.827711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba4cbe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T05:05:36.243361Z",
     "iopub.status.busy": "2022-03-19T05:05:36.242774Z",
     "iopub.status.idle": "2022-03-19T05:05:36.250382Z",
     "shell.execute_reply": "2022-03-19T05:05:36.249717Z",
     "shell.execute_reply.started": "2022-03-19T05:05:36.243323Z"
    },
    "papermill": {
     "duration": 0.030986,
     "end_time": "2022-03-19T22:42:20.936959",
     "exception": false,
     "start_time": "2022-03-19T22:42:20.905973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "class SymmetricCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=0.1, beta=1.0, num_classes=5):\n",
    "        super(SymmetricCrossEntropy, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets, reduction='mean'):\n",
    "        onehot_targets = torch.eye(self.num_classes)[targets].cuda()\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction=reduction)\n",
    "        rce_loss = (-onehot_targets*logits.softmax(1).clamp(1e-7, 1.0).log()).sum(1)\n",
    "        if reduction == 'mean':\n",
    "            rce_loss = rce_loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            rce_loss = rce_loss.sum()\n",
    "        return self.alpha * ce_loss + self.beta * rce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55cb6fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:21.006997Z",
     "iopub.status.busy": "2022-03-19T22:42:21.006280Z",
     "iopub.status.idle": "2022-03-19T22:42:21.008889Z",
     "shell.execute_reply": "2022-03-19T22:42:21.008455Z",
     "shell.execute_reply.started": "2022-03-19T22:32:58.039186Z"
    },
    "papermill": {
     "duration": 0.041325,
     "end_time": "2022-03-19T22:42:21.009001",
     "exception": false,
     "start_time": "2022-03-19T22:42:20.967676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "#from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=1e-4, weight_decay=1e-6, amsgrad=False)\n",
    "\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 3)\n",
    "scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n",
    "scheduler = scheduler_warmup\n",
    "criterion = FocalLoss().to(device)\n",
    "#criterion = SymmetricCrossEntropy().to(device)\n",
    "#TaylorCrossEntropyLoss(smoothing=0.05).to(device)\n",
    "best_score = 0.\n",
    "best_loss = np.inf\n",
    "config_device = \"GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "834f2e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:21.077276Z",
     "iopub.status.busy": "2022-03-19T22:42:21.076661Z",
     "iopub.status.idle": "2022-03-19T22:42:21.079336Z",
     "shell.execute_reply": "2022-03-19T22:42:21.078887Z",
     "shell.execute_reply.started": "2022-03-19T22:33:01.052356Z"
    },
    "papermill": {
     "duration": 0.040139,
     "end_time": "2022-03-19T22:42:21.079471",
     "exception": false,
     "start_time": "2022-03-19T22:42:21.039332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "949697d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:21.155252Z",
     "iopub.status.busy": "2022-03-19T22:42:21.153624Z",
     "iopub.status.idle": "2022-03-19T22:42:21.176812Z",
     "shell.execute_reply": "2022-03-19T22:42:21.177725Z",
     "shell.execute_reply.started": "2022-03-19T22:33:03.409317Z"
    },
    "papermill": {
     "duration": 0.06836,
     "end_time": "2022-03-19T22:42:21.177930",
     "exception": false,
     "start_time": "2022-03-19T22:42:21.109570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with autocast():\n",
    "            y_preds = model(images)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(loss.item(), batch_size)\n",
    "#             if CFG.gradient_accumulation_steps > 1:\n",
    "#                 loss = loss / CFG.gradient_accumulation_steps\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1000)\n",
    "            if (step + 1) % 1 == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % 100 == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  #'LR: {lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   grad_norm=grad_norm,\n",
    "                   #lr=scheduler.get_lr()[0],\n",
    "                   ))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "#         if CFG.gradient_accumulation_steps > 1:\n",
    "#             loss = loss / CFG.gradient_accumulation_steps\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % 100 == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions, trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62d361fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:21.305550Z",
     "iopub.status.busy": "2022-03-19T22:42:21.304723Z",
     "iopub.status.idle": "2022-03-19T22:42:22.063246Z",
     "shell.execute_reply": "2022-03-19T22:42:22.062787Z",
     "shell.execute_reply.started": "2022-03-19T22:33:07.498081Z"
    },
    "papermill": {
     "duration": 0.824503,
     "end_time": "2022-03-19T22:42:22.063419",
     "exception": false,
     "start_time": "2022-03-19T22:42:21.238916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fcbd62e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:42:22.128166Z",
     "iopub.status.busy": "2022-03-19T22:42:22.127677Z",
     "iopub.status.idle": "2022-03-19T22:43:36.664138Z",
     "shell.execute_reply": "2022-03-19T22:43:36.664586Z",
     "shell.execute_reply.started": "2022-03-19T22:33:08.90975Z"
    },
    "papermill": {
     "duration": 74.570333,
     "end_time": "2022-03-19T22:43:36.664737",
     "exception": false,
     "start_time": "2022-03-19T22:42:22.094404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4573,\n",
       " 0,\n",
       " 0,\n",
       " 2728,\n",
       " 4608,\n",
       " 0,\n",
       " 1194,\n",
       " 0,\n",
       " 0,\n",
       " 253,\n",
       " 3604,\n",
       " 4713,\n",
       " 3468,\n",
       " 4935,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1168,\n",
       " 64,\n",
       " 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_labels = []\n",
    "for img, labels in validation_loader:\n",
    "    valid_labels += labels.tolist()\n",
    "valid_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e41e62b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T22:43:36.732569Z",
     "iopub.status.busy": "2022-03-19T22:43:36.731805Z",
     "iopub.status.idle": "2022-03-19T23:49:39.152516Z",
     "shell.execute_reply": "2022-03-19T23:49:39.153039Z"
    },
    "papermill": {
     "duration": 3962.458888,
     "end_time": "2022-03-19T23:49:39.153193",
     "exception": false,
     "start_time": "2022-03-19T22:43:36.694305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/1348] Data 0.314 (0.314) Elapsed 0m 6s (remain 143m 15s) Loss: 8.4882(8.4882) Grad: nan  \n",
      "Epoch: [1][100/1348] Data 0.311 (0.317) Elapsed 0m 59s (remain 12m 11s) Loss: 6.0186(7.6575) Grad: 65433.7266  \n",
      "Epoch: [1][200/1348] Data 0.306 (0.319) Elapsed 1m 52s (remain 10m 42s) Loss: 5.1253(6.9178) Grad: 55036.4609  \n",
      "Epoch: [1][300/1348] Data 0.289 (0.315) Elapsed 2m 44s (remain 9m 32s) Loss: 3.8588(6.4916) Grad: 78943.3125  \n",
      "Epoch: [1][400/1348] Data 0.285 (0.315) Elapsed 3m 37s (remain 8m 33s) Loss: 5.2456(6.3271) Grad: 35148.0234  \n",
      "Epoch: [1][500/1348] Data 0.469 (0.316) Elapsed 4m 30s (remain 7m 37s) Loss: 3.8123(6.2275) Grad: 22299.3516  \n",
      "Epoch: [1][600/1348] Data 0.335 (0.316) Elapsed 5m 22s (remain 6m 41s) Loss: 5.1759(6.1771) Grad: 43647.6914  \n",
      "Epoch: [1][700/1348] Data 0.324 (0.317) Elapsed 6m 16s (remain 5m 47s) Loss: 4.9482(6.1520) Grad: 10811.5928  \n",
      "Epoch: [1][800/1348] Data 0.329 (0.316) Elapsed 7m 8s (remain 4m 52s) Loss: 7.0412(6.1358) Grad: 10155.7812  \n",
      "Epoch: [1][900/1348] Data 0.299 (0.316) Elapsed 8m 1s (remain 3m 59s) Loss: 7.4844(6.0950) Grad: 11212.4463  \n",
      "Epoch: [1][1000/1348] Data 0.326 (0.317) Elapsed 8m 55s (remain 3m 5s) Loss: 6.2776(6.0793) Grad: 12558.2217  \n",
      "Epoch: [1][1100/1348] Data 0.278 (0.316) Elapsed 9m 47s (remain 2m 11s) Loss: 6.3207(6.0591) Grad: 9126.1865  \n",
      "Epoch: [1][1200/1348] Data 0.437 (0.316) Elapsed 10m 40s (remain 1m 18s) Loss: 4.4737(6.0376) Grad: 8967.7490  \n",
      "Epoch: [1][1300/1348] Data 0.385 (0.317) Elapsed 11m 33s (remain 0m 25s) Loss: 6.1337(6.0194) Grad: 5029.6963  \n",
      "Epoch: [1][1347/1348] Data 0.104 (0.316) Elapsed 11m 57s (remain 0m 0s) Loss: 5.6011(6.0175) Grad: 9221.8135  \n",
      "EVAL: [0/238] Data 0.291 (0.291) Elapsed 0m 0s (remain 1m 22s) Loss: 6.4565(6.4565) \n",
      "EVAL: [100/238] Data 0.293 (0.307) Elapsed 0m 37s (remain 0m 50s) Loss: 5.0517(5.6822) \n",
      "EVAL: [200/238] Data 0.318 (0.312) Elapsed 1m 14s (remain 0m 13s) Loss: 5.3774(5.6812) \n",
      "EVAL: [237/238] Data 0.239 (0.313) Elapsed 1m 28s (remain 0m 0s) Loss: 7.2537(5.6999) \n",
      "Epoch 1 - avg_train_loss: 6.0175  avg_val_loss: 5.6999  time: 807s\n",
      "Epoch 1 - Score: 0.3838\n",
      "Epoch 1 - Save Best Score: 0.3838 Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/1348] Data 0.312 (0.312) Elapsed 0m 0s (remain 11m 49s) Loss: 5.9058(5.9058) Grad: inf  \n",
      "Epoch: [2][100/1348] Data 0.292 (0.323) Elapsed 0m 54s (remain 11m 7s) Loss: 6.6177(5.2394) Grad: 92160.7188  \n",
      "Epoch: [2][200/1348] Data 0.294 (0.314) Elapsed 1m 45s (remain 10m 3s) Loss: 4.8330(5.3297) Grad: 61104.9141  \n",
      "Epoch: [2][300/1348] Data 0.263 (0.313) Elapsed 2m 38s (remain 9m 9s) Loss: 5.9034(5.2698) Grad: 89850.5469  \n",
      "Epoch: [2][400/1348] Data 0.287 (0.312) Elapsed 3m 30s (remain 8m 16s) Loss: 5.5849(5.2967) Grad: 63200.7461  \n",
      "Epoch: [2][500/1348] Data 0.302 (0.311) Elapsed 4m 22s (remain 7m 23s) Loss: 4.3493(5.3048) Grad: 44264.0703  \n",
      "Epoch: [2][600/1348] Data 0.288 (0.311) Elapsed 5m 14s (remain 6m 30s) Loss: 4.9935(5.2748) Grad: 45702.1250  \n",
      "Epoch: [2][700/1348] Data 0.266 (0.310) Elapsed 6m 6s (remain 5m 37s) Loss: 3.4004(5.2699) Grad: 31859.1855  \n",
      "Epoch: [2][800/1348] Data 0.285 (0.310) Elapsed 6m 58s (remain 4m 45s) Loss: 4.7408(5.2517) Grad: 41697.4570  \n",
      "Epoch: [2][900/1348] Data 0.917 (0.310) Elapsed 7m 50s (remain 3m 53s) Loss: 4.7005(5.2433) Grad: 37178.5625  \n",
      "Epoch: [2][1000/1348] Data 0.283 (0.310) Elapsed 8m 42s (remain 3m 1s) Loss: 6.4016(5.2479) Grad: 45719.6289  \n",
      "Epoch: [2][1100/1348] Data 0.277 (0.310) Elapsed 9m 35s (remain 2m 9s) Loss: 5.2641(5.2565) Grad: 41596.9414  \n",
      "Epoch: [2][1200/1348] Data 0.292 (0.310) Elapsed 10m 26s (remain 1m 16s) Loss: 6.3743(5.2553) Grad: 35366.9531  \n",
      "Epoch: [2][1300/1348] Data 0.289 (0.310) Elapsed 11m 19s (remain 0m 24s) Loss: 5.4791(5.2496) Grad: 42330.0898  \n",
      "Epoch: [2][1347/1348] Data 0.099 (0.310) Elapsed 11m 43s (remain 0m 0s) Loss: 4.9162(5.2543) Grad: 72005.1406  \n",
      "EVAL: [0/238] Data 0.322 (0.322) Elapsed 0m 0s (remain 1m 29s) Loss: 5.6798(5.6798) \n",
      "EVAL: [100/238] Data 0.313 (0.306) Elapsed 0m 37s (remain 0m 50s) Loss: 4.4401(5.4818) \n",
      "EVAL: [200/238] Data 0.428 (0.306) Elapsed 1m 13s (remain 0m 13s) Loss: 6.0705(5.5000) \n",
      "EVAL: [237/238] Data 0.249 (0.307) Elapsed 1m 27s (remain 0m 0s) Loss: 5.1578(5.4497) \n",
      "Epoch 2 - avg_train_loss: 5.2543  avg_val_loss: 5.4497  time: 792s\n",
      "Epoch 2 - Score: 0.3838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/1348] Data 0.504 (0.504) Elapsed 0m 0s (remain 16m 7s) Loss: 5.6654(5.6654) Grad: inf  \n",
      "Epoch: [3][100/1348] Data 0.500 (0.307) Elapsed 0m 52s (remain 10m 48s) Loss: 6.9765(5.2384) Grad: 47101.6562  \n",
      "Epoch: [3][200/1348] Data 0.318 (0.310) Elapsed 1m 44s (remain 9m 58s) Loss: 4.6469(5.2254) Grad: 31249.5273  \n",
      "Epoch: [3][300/1348] Data 0.281 (0.308) Elapsed 2m 36s (remain 9m 4s) Loss: 5.9456(5.1819) Grad: 26572.6641  \n",
      "Epoch: [3][400/1348] Data 0.329 (0.309) Elapsed 3m 29s (remain 8m 14s) Loss: 4.4317(5.1181) Grad: 19016.8867  \n",
      "Epoch: [3][500/1348] Data 0.300 (0.308) Elapsed 4m 20s (remain 7m 20s) Loss: 4.8906(5.0900) Grad: 24017.3691  \n",
      "Epoch: [3][600/1348] Data 0.292 (0.310) Elapsed 5m 13s (remain 6m 29s) Loss: 5.4923(5.0604) Grad: 18708.3359  \n",
      "Epoch: [3][700/1348] Data 0.300 (0.310) Elapsed 6m 6s (remain 5m 38s) Loss: 3.6025(4.9842) Grad: 15280.1123  \n",
      "Epoch: [3][800/1348] Data 0.277 (0.310) Elapsed 6m 58s (remain 4m 45s) Loss: 5.3315(4.9276) Grad: 17394.8750  \n",
      "Epoch: [3][900/1348] Data 0.445 (0.309) Elapsed 7m 50s (remain 3m 53s) Loss: 4.1650(4.8733) Grad: 19293.5625  \n",
      "Epoch: [3][1000/1348] Data 0.299 (0.309) Elapsed 8m 42s (remain 3m 0s) Loss: 5.0919(4.8394) Grad: 20542.2227  \n",
      "Epoch: [3][1100/1348] Data 0.283 (0.309) Elapsed 9m 34s (remain 2m 8s) Loss: 5.3058(4.7903) Grad: 19133.5605  \n",
      "Epoch: [3][1200/1348] Data 0.300 (0.309) Elapsed 10m 26s (remain 1m 16s) Loss: 4.4496(4.7426) Grad: 19176.4316  \n",
      "Epoch: [3][1300/1348] Data 0.296 (0.309) Elapsed 11m 17s (remain 0m 24s) Loss: 3.3467(4.7028) Grad: 16589.2148  \n",
      "Epoch: [3][1347/1348] Data 0.155 (0.309) Elapsed 11m 42s (remain 0m 0s) Loss: 5.1506(4.6748) Grad: 36297.7539  \n",
      "EVAL: [0/238] Data 0.313 (0.313) Elapsed 0m 0s (remain 1m 27s) Loss: 4.1352(4.1352) \n",
      "EVAL: [100/238] Data 0.294 (0.303) Elapsed 0m 36s (remain 0m 49s) Loss: 4.2373(4.6469) \n",
      "EVAL: [200/238] Data 0.278 (0.305) Elapsed 1m 13s (remain 0m 13s) Loss: 4.6949(4.6482) \n",
      "EVAL: [237/238] Data 0.258 (0.307) Elapsed 1m 27s (remain 0m 0s) Loss: 4.2126(4.6351) \n",
      "Epoch 3 - avg_train_loss: 4.6748  avg_val_loss: 4.6351  time: 790s\n",
      "Epoch 3 - Score: 0.3449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:972: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/1348] Data 0.314 (0.314) Elapsed 0m 0s (remain 11m 43s) Loss: 3.0765(3.0765) Grad: inf  \n",
      "Epoch: [4][100/1348] Data 0.283 (0.304) Elapsed 0m 52s (remain 10m 42s) Loss: 4.0362(2.9818) Grad: 39591.0664  \n",
      "Epoch: [4][200/1348] Data 0.296 (0.305) Elapsed 1m 44s (remain 9m 53s) Loss: 3.1582(2.8102) Grad: 44106.3047  \n",
      "Epoch: [4][300/1348] Data 0.286 (0.307) Elapsed 2m 36s (remain 9m 4s) Loss: 1.9992(2.7050) Grad: 39863.4688  \n",
      "Epoch: [4][400/1348] Data 0.296 (0.306) Elapsed 3m 27s (remain 8m 10s) Loss: 1.8298(2.6637) Grad: 41702.4258  \n",
      "Epoch: [4][500/1348] Data 0.318 (0.307) Elapsed 4m 20s (remain 7m 19s) Loss: 2.4465(2.6256) Grad: 53659.7109  \n",
      "Epoch: [4][600/1348] Data 0.260 (0.306) Elapsed 5m 11s (remain 6m 27s) Loss: 1.3888(2.5901) Grad: 43884.8672  \n",
      "Epoch: [4][700/1348] Data 0.328 (0.307) Elapsed 6m 4s (remain 5m 36s) Loss: 1.0368(2.5492) Grad: 46141.7070  \n",
      "Epoch: [4][800/1348] Data 0.275 (0.308) Elapsed 6m 56s (remain 4m 44s) Loss: 1.3158(2.5349) Grad: 52639.6133  \n",
      "Epoch: [4][900/1348] Data 0.291 (0.307) Elapsed 7m 48s (remain 3m 52s) Loss: 1.2086(2.5196) Grad: 38681.2500  \n",
      "Epoch: [4][1000/1348] Data 0.262 (0.308) Elapsed 8m 41s (remain 3m 0s) Loss: 1.8469(2.5203) Grad: 44498.9922  \n",
      "Epoch: [4][1100/1348] Data 0.292 (0.310) Elapsed 9m 35s (remain 2m 9s) Loss: 2.1378(2.5147) Grad: 56402.2109  \n",
      "Epoch: [4][1200/1348] Data 0.450 (0.309) Elapsed 10m 26s (remain 1m 16s) Loss: 2.7732(2.5052) Grad: 42978.6562  \n",
      "Epoch: [4][1300/1348] Data 0.280 (0.309) Elapsed 11m 18s (remain 0m 24s) Loss: 1.3453(2.4918) Grad: 44151.4844  \n",
      "Epoch: [4][1347/1348] Data 0.105 (0.309) Elapsed 11m 42s (remain 0m 0s) Loss: 3.5628(2.4911) Grad: 108617.9453  \n",
      "EVAL: [0/238] Data 0.400 (0.400) Elapsed 0m 0s (remain 1m 48s) Loss: 3.6063(3.6063) \n",
      "EVAL: [100/238] Data 0.269 (0.313) Elapsed 0m 37s (remain 0m 50s) Loss: 3.7306(4.1017) \n",
      "EVAL: [200/238] Data 0.272 (0.307) Elapsed 1m 13s (remain 0m 13s) Loss: 5.0356(3.9226) \n",
      "EVAL: [237/238] Data 0.234 (0.306) Elapsed 1m 26s (remain 0m 0s) Loss: 2.2598(3.9264) \n",
      "Epoch 4 - avg_train_loss: 2.4911  avg_val_loss: 3.9264  time: 789s\n",
      "Epoch 4 - Score: 0.2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/1348] Data 0.306 (0.306) Elapsed 0m 0s (remain 11m 36s) Loss: 1.1596(1.1596) Grad: inf  \n",
      "Epoch: [5][100/1348] Data 0.261 (0.309) Elapsed 0m 52s (remain 10m 50s) Loss: 0.2308(0.9449) Grad: 20387.1738  \n",
      "Epoch: [5][200/1348] Data 0.288 (0.309) Elapsed 1m 44s (remain 9m 57s) Loss: 0.5297(0.8007) Grad: 36687.7031  \n",
      "Epoch: [5][300/1348] Data 0.352 (0.309) Elapsed 2m 36s (remain 9m 5s) Loss: 0.0626(0.7349) Grad: 10205.4375  \n",
      "Epoch: [5][400/1348] Data 0.306 (0.306) Elapsed 3m 27s (remain 8m 10s) Loss: 0.6695(0.6838) Grad: 39964.5273  \n",
      "Epoch: [5][500/1348] Data 0.296 (0.306) Elapsed 4m 19s (remain 7m 19s) Loss: 0.5209(0.6353) Grad: 33711.8906  \n",
      "Epoch: [5][600/1348] Data 0.289 (0.306) Elapsed 5m 11s (remain 6m 27s) Loss: 0.1626(0.6113) Grad: 17527.6895  \n",
      "Epoch: [5][700/1348] Data 0.263 (0.305) Elapsed 6m 2s (remain 5m 34s) Loss: 0.3057(0.5902) Grad: 22306.9141  \n",
      "Epoch: [5][800/1348] Data 0.293 (0.306) Elapsed 6m 54s (remain 4m 43s) Loss: 0.2006(0.5754) Grad: 21478.1465  \n",
      "Epoch: [5][900/1348] Data 0.289 (0.306) Elapsed 7m 47s (remain 3m 51s) Loss: 0.4537(0.5545) Grad: 40679.7812  \n",
      "Epoch: [5][1000/1348] Data 0.276 (0.306) Elapsed 8m 38s (remain 2m 59s) Loss: 0.3396(0.5379) Grad: 32623.1445  \n",
      "Epoch: [5][1100/1348] Data 0.273 (0.306) Elapsed 9m 30s (remain 2m 7s) Loss: 0.4320(0.5295) Grad: 38686.5938  \n",
      "Epoch: [5][1200/1348] Data 0.295 (0.306) Elapsed 10m 22s (remain 1m 16s) Loss: 0.1138(0.5197) Grad: 15681.0957  \n",
      "Epoch: [5][1300/1348] Data 0.436 (0.306) Elapsed 11m 13s (remain 0m 24s) Loss: 0.5562(0.5127) Grad: 42387.1367  \n",
      "Epoch: [5][1347/1348] Data 0.097 (0.305) Elapsed 11m 37s (remain 0m 0s) Loss: 3.0256(0.5067) Grad: 142204.1406  \n",
      "EVAL: [0/238] Data 0.293 (0.293) Elapsed 0m 0s (remain 1m 22s) Loss: 4.3236(4.3236) \n",
      "EVAL: [100/238] Data 0.287 (0.304) Elapsed 0m 36s (remain 0m 49s) Loss: 0.6574(3.5645) \n",
      "EVAL: [200/238] Data 0.296 (0.303) Elapsed 1m 12s (remain 0m 13s) Loss: 2.2257(3.5218) \n",
      "EVAL: [237/238] Data 0.233 (0.302) Elapsed 1m 26s (remain 0m 0s) Loss: 3.4446(3.5012) \n",
      "Epoch 5 - avg_train_loss: 0.5067  avg_val_loss: 3.5012  time: 784s\n",
      "Epoch 5 - Score: 0.2040\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for epoch in range(5):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    avg_loss = train_fn(train_loader, m, criterion, optimizer, epoch, scheduler, device)\n",
    "    avg_val_loss, preds, _ = valid_fn(validation_loader, m, criterion, device)\n",
    "    \n",
    "#     if isinstance(scheduler, ReduceLROnPlateau):\n",
    "#         scheduler.step(avg_val_loss)\n",
    "#     elif isinstance(scheduler, CosineAnnealingLR):\n",
    "#         scheduler.step()\n",
    "#     elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "#         scheduler.step()\n",
    "#     el\n",
    "    if isinstance(scheduler, GradualWarmupSchedulerV2):\n",
    "        scheduler.step(epoch)\n",
    "\n",
    "    score = get_score(valid_labels, preds.argmax(1))\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "    print(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "        torch.save({'model': m.state_dict(), \n",
    "                        'preds': preds},\n",
    "                       'best_score.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cacac2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T23:49:39.283071Z",
     "iopub.status.busy": "2022-03-19T23:49:39.282281Z",
     "iopub.status.idle": "2022-03-19T23:50:42.811221Z",
     "shell.execute_reply": "2022-03-19T23:50:42.810316Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.878206Z"
    },
    "papermill": {
     "duration": 63.595906,
     "end_time": "2022-03-19T23:50:42.811382",
     "exception": false,
     "start_time": "2022-03-19T23:49:39.215476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! mkdir ./testholder\n",
    "! cp -r ../input/humpback-whale-identification/test ./testholder/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67f7c1bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T23:50:42.942281Z",
     "iopub.status.busy": "2022-03-19T23:50:42.941515Z",
     "iopub.status.idle": "2022-03-19T23:50:42.987782Z",
     "shell.execute_reply": "2022-03-19T23:50:42.987238Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.880035Z"
    },
    "papermill": {
     "duration": 0.11339,
     "end_time": "2022-03-19T23:50:42.987897",
     "exception": false,
     "start_time": "2022-03-19T23:50:42.874507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_img = datasets.ImageFolder('./testholder', transform=transform)\n",
    "submission_loader = torch.utils.data.DataLoader(submission_img, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb6ba0d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T23:50:43.122784Z",
     "iopub.status.busy": "2022-03-19T23:50:43.121955Z",
     "iopub.status.idle": "2022-03-19T23:50:43.124755Z",
     "shell.execute_reply": "2022-03-19T23:50:43.125305Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.881861Z"
    },
    "papermill": {
     "duration": 0.075055,
     "end_time": "2022-03-19T23:50:43.125472",
     "exception": false,
     "start_time": "2022-03-19T23:50:43.050417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00028a005.jpg',\n",
       " '000dcf7d8.jpg',\n",
       " '000e7c7df.jpg',\n",
       " '0019c34f4.jpg',\n",
       " '001a4d292.jpg',\n",
       " '00247bc36.jpg',\n",
       " '0027089a4.jpg',\n",
       " '002de4d94.jpg',\n",
       " '002f52f0c.jpg',\n",
       " '002fd89d4.jpg',\n",
       " '00313e2d2.jpg',\n",
       " '00379666f.jpg',\n",
       " '0041a9867.jpg',\n",
       " '004344e9f.jpg',\n",
       " '0048970f9.jpg',\n",
       " '004fa8ff7.jpg',\n",
       " '00512687e.jpg',\n",
       " '006183fb4.jpg',\n",
       " '0061febfc.jpg',\n",
       " '0065d4964.jpg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "for path, idx in submission_img.imgs:\n",
    "    filenames.append(path[path.index('test/') + 5:])\n",
    "filenames[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eccc5def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T23:50:43.270002Z",
     "iopub.status.busy": "2022-03-19T23:50:43.259048Z",
     "iopub.status.idle": "2022-03-19T23:50:43.289624Z",
     "shell.execute_reply": "2022-03-19T23:50:43.290012Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.883692Z"
    },
    "papermill": {
     "duration": 0.099936,
     "end_time": "2022-03-19T23:50:43.290127",
     "exception": false,
     "start_time": "2022-03-19T23:50:43.190191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'new_whale',\n",
       " 1: 'w_0003639',\n",
       " 2: 'w_0003c59',\n",
       " 3: 'w_0027efa',\n",
       " 4: 'w_00289b1',\n",
       " 5: 'w_002c810',\n",
       " 6: 'w_0032a46',\n",
       " 7: 'w_003bae6',\n",
       " 8: 'w_00656c0',\n",
       " 9: 'w_0066399',\n",
       " 10: 'w_007fefa',\n",
       " 11: 'w_00904a7',\n",
       " 12: 'w_009c9c5',\n",
       " 13: 'w_00a41ba',\n",
       " 14: 'w_00b3dc2',\n",
       " 15: 'w_00d50c9',\n",
       " 16: 'w_00d5466',\n",
       " 17: 'w_00d5e98',\n",
       " 18: 'w_00f340d',\n",
       " 19: 'w_010f858',\n",
       " 20: 'w_0115c24',\n",
       " 21: 'w_0118bab',\n",
       " 22: 'w_012678c',\n",
       " 23: 'w_0135f5f',\n",
       " 24: 'w_0140c92',\n",
       " 25: 'w_015a4bf',\n",
       " 26: 'w_016f0ea',\n",
       " 27: 'w_0182687',\n",
       " 28: 'w_0189b6d',\n",
       " 29: 'w_01976db',\n",
       " 30: 'w_01a1d88',\n",
       " 31: 'w_01cb0c4',\n",
       " 32: 'w_01cbbbd',\n",
       " 33: 'w_01d790e',\n",
       " 34: 'w_01e1b97',\n",
       " 35: 'w_01e1fe0',\n",
       " 36: 'w_01ed442',\n",
       " 37: 'w_01f14e1',\n",
       " 38: 'w_01fc429',\n",
       " 39: 'w_02156b0',\n",
       " 40: 'w_022b708',\n",
       " 41: 'w_022d2f5',\n",
       " 42: 'w_02469a1',\n",
       " 43: 'w_02545ea',\n",
       " 44: 'w_025911c',\n",
       " 45: 'w_0277a07',\n",
       " 46: 'w_027f528',\n",
       " 47: 'w_0292e15',\n",
       " 48: 'w_02aa597',\n",
       " 49: 'w_02c7e9d',\n",
       " 50: 'w_02d138d',\n",
       " 51: 'w_02d5c46',\n",
       " 52: 'w_02e8199',\n",
       " 53: 'w_02ff6d6',\n",
       " 54: 'w_0301302',\n",
       " 55: 'w_030ac9b',\n",
       " 56: 'w_030c8b0',\n",
       " 57: 'w_030e2cf',\n",
       " 58: 'w_03193e5',\n",
       " 59: 'w_031e1a3',\n",
       " 60: 'w_0323574',\n",
       " 61: 'w_03270e3',\n",
       " 62: 'w_0350bf4',\n",
       " 63: 'w_03670aa',\n",
       " 64: 'w_0369a5c',\n",
       " 65: 'w_036bc54',\n",
       " 66: 'w_036dbd0',\n",
       " 67: 'w_037b23f',\n",
       " 68: 'w_038dfc0',\n",
       " 69: 'w_038e5c3',\n",
       " 70: 'w_03a82c1',\n",
       " 71: 'w_03ad89c',\n",
       " 72: 'w_03e3e5e',\n",
       " 73: 'w_03ea6f9',\n",
       " 74: 'w_04003e9',\n",
       " 75: 'w_042b547',\n",
       " 76: 'w_0470377',\n",
       " 77: 'w_04713fd',\n",
       " 78: 'w_04738c8',\n",
       " 79: 'w_048bc73',\n",
       " 80: 'w_049ae2e',\n",
       " 81: 'w_04acf95',\n",
       " 82: 'w_04c9b23',\n",
       " 83: 'w_04d1c8c',\n",
       " 84: 'w_04d4568',\n",
       " 85: 'w_04de239',\n",
       " 86: 'w_04ebfe8',\n",
       " 87: 'w_04f5a19',\n",
       " 88: 'w_04f5f55',\n",
       " 89: 'w_05081a8',\n",
       " 90: 'w_0513962',\n",
       " 91: 'w_051764c',\n",
       " 92: 'w_0531ad5',\n",
       " 93: 'w_0532483',\n",
       " 94: 'w_054162a',\n",
       " 95: 'w_05669fe',\n",
       " 96: 'w_056710d',\n",
       " 97: 'w_056913a',\n",
       " 98: 'w_0577ccc',\n",
       " 99: 'w_059d9e0',\n",
       " 100: 'w_05b4b0c',\n",
       " 101: 'w_05bf34e',\n",
       " 102: 'w_05cc23c',\n",
       " 103: 'w_05d52d0',\n",
       " 104: 'w_05d65b9',\n",
       " 105: 'w_05eb863',\n",
       " 106: 'w_05f8c99',\n",
       " 107: 'w_05fbf14',\n",
       " 108: 'w_060ec6d',\n",
       " 109: 'w_06150e1',\n",
       " 110: 'w_06292cd',\n",
       " 111: 'w_0630c3e',\n",
       " 112: 'w_06313c8',\n",
       " 113: 'w_063282e',\n",
       " 114: 'w_0637181',\n",
       " 115: 'w_06376db',\n",
       " 116: 'w_06460d7',\n",
       " 117: 'w_06471d5',\n",
       " 118: 'w_0655608',\n",
       " 119: 'w_0655a0d',\n",
       " 120: 'w_065ee1b',\n",
       " 121: 'w_06619ff',\n",
       " 122: 'w_066ac1a',\n",
       " 123: 'w_066ddc5',\n",
       " 124: 'w_068baa8',\n",
       " 125: 'w_06935ed',\n",
       " 126: 'w_069c25b',\n",
       " 127: 'w_06a10b4',\n",
       " 128: 'w_06d2e72',\n",
       " 129: 'w_06de0a6',\n",
       " 130: 'w_06e4776',\n",
       " 131: 'w_06e6d5f',\n",
       " 132: 'w_06ec6e6',\n",
       " 133: 'w_06f3291',\n",
       " 134: 'w_06fb64a',\n",
       " 135: 'w_06ffb30',\n",
       " 136: 'w_070036a',\n",
       " 137: 'w_07019f4',\n",
       " 138: 'w_07125ed',\n",
       " 139: 'w_0714a46',\n",
       " 140: 'w_0717f05',\n",
       " 141: 'w_0718183',\n",
       " 142: 'w_072179d',\n",
       " 143: 'w_0729126',\n",
       " 144: 'w_072f593',\n",
       " 145: 'w_0741282',\n",
       " 146: 'w_074530d',\n",
       " 147: 'w_0745b0e',\n",
       " 148: 'w_0749e87',\n",
       " 149: 'w_074a5ba',\n",
       " 150: 'w_076bb5a',\n",
       " 151: 'w_07768b0',\n",
       " 152: 'w_0788c36',\n",
       " 153: 'w_07c946d',\n",
       " 154: 'w_07cb113',\n",
       " 155: 'w_07cc9c2',\n",
       " 156: 'w_07d4b0a',\n",
       " 157: 'w_07e0c3c',\n",
       " 158: 'w_08010cc',\n",
       " 159: 'w_0815d2c',\n",
       " 160: 'w_0823d50',\n",
       " 161: 'w_082978e',\n",
       " 162: 'w_082f603',\n",
       " 163: 'w_0833a92',\n",
       " 164: 'w_08630fd',\n",
       " 165: 'w_086f404',\n",
       " 166: 'w_08753b7',\n",
       " 167: 'w_0886321',\n",
       " 168: 'w_0887d9b',\n",
       " 169: 'w_0888e56',\n",
       " 170: 'w_088cda7',\n",
       " 171: 'w_08b0eac',\n",
       " 172: 'w_08c7d09',\n",
       " 173: 'w_08d439c',\n",
       " 174: 'w_08d5864',\n",
       " 175: 'w_08d62ee',\n",
       " 176: 'w_08eadf6',\n",
       " 177: 'w_090c08a',\n",
       " 178: 'w_090c801',\n",
       " 179: 'w_091ec23',\n",
       " 180: 'w_0926777',\n",
       " 181: 'w_092d942',\n",
       " 182: 'w_093d284',\n",
       " 183: 'w_093ea58',\n",
       " 184: 'w_095e3eb',\n",
       " 185: 'w_099bcbc',\n",
       " 186: 'w_09bd7e8',\n",
       " 187: 'w_09c59c2',\n",
       " 188: 'w_09c737d',\n",
       " 189: 'w_09c8a69',\n",
       " 190: 'w_09de1a5',\n",
       " 191: 'w_09e51f8',\n",
       " 192: 'w_0a0b4c6',\n",
       " 193: 'w_0a0c768',\n",
       " 194: 'w_0a155b9',\n",
       " 195: 'w_0a1fcd6',\n",
       " 196: 'w_0a2e1ef',\n",
       " 197: 'w_0a31a3a',\n",
       " 198: 'w_0a3255c',\n",
       " 199: 'w_0a357b7',\n",
       " 200: 'w_0a4f5c9',\n",
       " 201: 'w_0a619af',\n",
       " 202: 'w_0a6c4c7',\n",
       " 203: 'w_0a6e626',\n",
       " 204: 'w_0a7a37c',\n",
       " 205: 'w_0a84ac5',\n",
       " 206: 'w_0a87ea4',\n",
       " 207: 'w_0a8a451',\n",
       " 208: 'w_0a8d318',\n",
       " 209: 'w_0a8e080',\n",
       " 210: 'w_0abdaf4',\n",
       " 211: 'w_0abe9e7',\n",
       " 212: 'w_0ac10f3',\n",
       " 213: 'w_0ac1b5f',\n",
       " 214: 'w_0ad0f5b',\n",
       " 215: 'w_0ad1734',\n",
       " 216: 'w_0adb403',\n",
       " 217: 'w_0aea542',\n",
       " 218: 'w_0aed03f',\n",
       " 219: 'w_0af3867',\n",
       " 220: 'w_0b0168a',\n",
       " 221: 'w_0b10e7c',\n",
       " 222: 'w_0b1e4a6',\n",
       " 223: 'w_0b356c2',\n",
       " 224: 'w_0b398b2',\n",
       " 225: 'w_0b3e0e6',\n",
       " 226: 'w_0b4f7cf',\n",
       " 227: 'w_0b7ce1e',\n",
       " 228: 'w_0b995e5',\n",
       " 229: 'w_0b9cab4',\n",
       " 230: 'w_0baf946',\n",
       " 231: 'w_0bb71d3',\n",
       " 232: 'w_0bb9927',\n",
       " 233: 'w_0bbc3cb',\n",
       " 234: 'w_0bc078c',\n",
       " 235: 'w_0bc1de9',\n",
       " 236: 'w_0bd2e46',\n",
       " 237: 'w_0bd39c1',\n",
       " 238: 'w_0bdb7a5',\n",
       " 239: 'w_0bdc5d5',\n",
       " 240: 'w_0bf90d9',\n",
       " 241: 'w_0bfc890',\n",
       " 242: 'w_0bfdcca',\n",
       " 243: 'w_0c23936',\n",
       " 244: 'w_0c59853',\n",
       " 245: 'w_0c5f019',\n",
       " 246: 'w_0c69117',\n",
       " 247: 'w_0c76541',\n",
       " 248: 'w_0c76e03',\n",
       " 249: 'w_0c7ab0d',\n",
       " 250: 'w_0c80c53',\n",
       " 251: 'w_0ca546b',\n",
       " 252: 'w_0cadbdc',\n",
       " 253: 'w_0cbf1b3',\n",
       " 254: 'w_0cc0430',\n",
       " 255: 'w_0cdca97',\n",
       " 256: 'w_0ce0555',\n",
       " 257: 'w_0ce537a',\n",
       " 258: 'w_0cfae04',\n",
       " 259: 'w_0cfdaa5',\n",
       " 260: 'w_0d052c1',\n",
       " 261: 'w_0d11fa9',\n",
       " 262: 'w_0d145d4',\n",
       " 263: 'w_0d1b964',\n",
       " 264: 'w_0d43823',\n",
       " 265: 'w_0d4a14b',\n",
       " 266: 'w_0d54c55',\n",
       " 267: 'w_0d5a672',\n",
       " 268: 'w_0d5fa2c',\n",
       " 269: 'w_0d61101',\n",
       " 270: 'w_0d77f32',\n",
       " 271: 'w_0d7b050',\n",
       " 272: 'w_0d93517',\n",
       " 273: 'w_0d98e43',\n",
       " 274: 'w_0d9ddce',\n",
       " 275: 'w_0da34d3',\n",
       " 276: 'w_0da9a8f',\n",
       " 277: 'w_0db234e',\n",
       " 278: 'w_0db2e26',\n",
       " 279: 'w_0dc84fd',\n",
       " 280: 'w_0dd4a5d',\n",
       " 281: 'w_0df7caf',\n",
       " 282: 'w_0dfb4f6',\n",
       " 283: 'w_0dfc1eb',\n",
       " 284: 'w_0e0b65c',\n",
       " 285: 'w_0e0f074',\n",
       " 286: 'w_0e1eccb',\n",
       " 287: 'w_0e26d1a',\n",
       " 288: 'w_0e2a5bd',\n",
       " 289: 'w_0e2b483',\n",
       " 290: 'w_0e325b0',\n",
       " 291: 'w_0e34e76',\n",
       " 292: 'w_0e35358',\n",
       " 293: 'w_0e4b65e',\n",
       " 294: 'w_0e7aae1',\n",
       " 295: 'w_0e7ec27',\n",
       " 296: 'w_0e8341d',\n",
       " 297: 'w_0e93f25',\n",
       " 298: 'w_0e9f07a',\n",
       " 299: 'w_0ea7436',\n",
       " 300: 'w_0eab54f',\n",
       " 301: 'w_0ecda0a',\n",
       " 302: 'w_0ee1b0f',\n",
       " 303: 'w_0ee7878',\n",
       " 304: 'w_0ee9ae5',\n",
       " 305: 'w_0ef790d',\n",
       " 306: 'w_0f00df0',\n",
       " 307: 'w_0f031ca',\n",
       " 308: 'w_0f03c44',\n",
       " 309: 'w_0f0f15c',\n",
       " 310: 'w_0f1cf57',\n",
       " 311: 'w_0f25e3c',\n",
       " 312: 'w_0f25e6b',\n",
       " 313: 'w_0f466a5',\n",
       " 314: 'w_0f4d4ac',\n",
       " 315: 'w_0f5666b',\n",
       " 316: 'w_0f56fb2',\n",
       " 317: 'w_0f5d895',\n",
       " 318: 'w_0f73f48',\n",
       " 319: 'w_0f84e7c',\n",
       " 320: 'w_0f86e70',\n",
       " 321: 'w_0f8ab07',\n",
       " 322: 'w_0f8b8e2',\n",
       " 323: 'w_0fb38fe',\n",
       " 324: 'w_0fc3e41',\n",
       " 325: 'w_0fdde23',\n",
       " 326: 'w_0fdf741',\n",
       " 327: 'w_0fe07b7',\n",
       " 328: 'w_0fe6fbb',\n",
       " 329: 'w_0fedd59',\n",
       " 330: 'w_0fefc62',\n",
       " 331: 'w_0ffa15f',\n",
       " 332: 'w_1006b9c',\n",
       " 333: 'w_101990d',\n",
       " 334: 'w_102821e',\n",
       " 335: 'w_1029215',\n",
       " 336: 'w_102e715',\n",
       " 337: 'w_1032bb6',\n",
       " 338: 'w_1032fa3',\n",
       " 339: 'w_103aca2',\n",
       " 340: 'w_104d305',\n",
       " 341: 'w_105b860',\n",
       " 342: 'w_107b98e',\n",
       " 343: 'w_1082fdc',\n",
       " 344: 'w_1083a05',\n",
       " 345: 'w_108b2ed',\n",
       " 346: 'w_10a4e10',\n",
       " 347: 'w_10b4603',\n",
       " 348: 'w_10bb1ba',\n",
       " 349: 'w_10d9667',\n",
       " 350: 'w_10eece8',\n",
       " 351: 'w_10f3b75',\n",
       " 352: 'w_10f4afc',\n",
       " 353: 'w_10f67bb',\n",
       " 354: 'w_1104cca',\n",
       " 355: 'w_1106cbb',\n",
       " 356: 'w_112d2f8',\n",
       " 357: 'w_1133530',\n",
       " 358: 'w_114a297',\n",
       " 359: 'w_115e880',\n",
       " 360: 'w_1167daf',\n",
       " 361: 'w_118a4a4',\n",
       " 362: 'w_118fad5',\n",
       " 363: 'w_119f570',\n",
       " 364: 'w_11ac036',\n",
       " 365: 'w_11bd416',\n",
       " 366: 'w_11ce746',\n",
       " 367: 'w_11d8c70',\n",
       " 368: 'w_11e75bf',\n",
       " 369: 'w_11e90bc',\n",
       " 370: 'w_11ec829',\n",
       " 371: 'w_11ff425',\n",
       " 372: 'w_1217536',\n",
       " 373: 'w_1220336',\n",
       " 374: 'w_122e247',\n",
       " 375: 'w_122eec1',\n",
       " 376: 'w_1247b8c',\n",
       " 377: 'w_124a3cb',\n",
       " 378: 'w_1257748',\n",
       " 379: 'w_1260eb5',\n",
       " 380: 'w_1275240',\n",
       " 381: 'w_1286f9e',\n",
       " 382: 'w_1289b63',\n",
       " 383: 'w_12aae3e',\n",
       " 384: 'w_12b56df',\n",
       " 385: 'w_12cc52d',\n",
       " 386: 'w_12ce4f8',\n",
       " 387: 'w_12e7c23',\n",
       " 388: 'w_12e8dc7',\n",
       " 389: 'w_12fdac7',\n",
       " 390: 'w_12fe3a8',\n",
       " 391: 'w_13250ab',\n",
       " 392: 'w_1344da3',\n",
       " 393: 'w_13937e4',\n",
       " 394: 'w_139d19a',\n",
       " 395: 'w_13a7d9a',\n",
       " 396: 'w_13aa123',\n",
       " 397: 'w_13ae3d4',\n",
       " 398: 'w_13b343c',\n",
       " 399: 'w_13c1b55',\n",
       " 400: 'w_13c715a',\n",
       " 401: 'w_13c8177',\n",
       " 402: 'w_13c9277',\n",
       " 403: 'w_13c9a17',\n",
       " 404: 'w_13ca7e8',\n",
       " 405: 'w_13d4fd0',\n",
       " 406: 'w_13e8097',\n",
       " 407: 'w_13edc47',\n",
       " 408: 'w_13ffdcf',\n",
       " 409: 'w_1403973',\n",
       " 410: 'w_140a9ac',\n",
       " 411: 'w_1417bc8',\n",
       " 412: 'w_1419d90',\n",
       " 413: 'w_141a880',\n",
       " 414: 'w_1423c1f',\n",
       " 415: 'w_14330a0',\n",
       " 416: 'w_143ea92',\n",
       " 417: 'w_14461a7',\n",
       " 418: 'w_144ecb6',\n",
       " 419: 'w_1457f13',\n",
       " 420: 'w_146208a',\n",
       " 421: 'w_1472271',\n",
       " 422: 'w_1483be2',\n",
       " 423: 'w_148921b',\n",
       " 424: 'w_14a74dd',\n",
       " 425: 'w_14b1427',\n",
       " 426: 'w_14bfbe2',\n",
       " 427: 'w_14e1334',\n",
       " 428: 'w_14e5fe2',\n",
       " 429: 'w_14ece76',\n",
       " 430: 'w_14f15a0',\n",
       " 431: 'w_150a6f5',\n",
       " 432: 'w_1531bf5',\n",
       " 433: 'w_1554173',\n",
       " 434: 'w_1574bd1',\n",
       " 435: 'w_1579152',\n",
       " 436: 'w_15805cd',\n",
       " 437: 'w_15951db',\n",
       " 438: 'w_15a9ec1',\n",
       " 439: 'w_15b3f09',\n",
       " 440: 'w_15b5df2',\n",
       " 441: 'w_15b5eb1',\n",
       " 442: 'w_15bf3e3',\n",
       " 443: 'w_15bf4be',\n",
       " 444: 'w_15d12c7',\n",
       " 445: 'w_15e3099',\n",
       " 446: 'w_15e7de5',\n",
       " 447: 'w_15f43ea',\n",
       " 448: 'w_15fb899',\n",
       " 449: 'w_1632c45',\n",
       " 450: 'w_16362a6',\n",
       " 451: 'w_163b2b8',\n",
       " 452: 'w_1647882',\n",
       " 453: 'w_1650208',\n",
       " 454: 'w_1666216',\n",
       " 455: 'w_167a348',\n",
       " 456: 'w_1684cac',\n",
       " 457: 'w_169253a',\n",
       " 458: 'w_1693b27',\n",
       " 459: 'w_169a302',\n",
       " 460: 'w_16a13bb',\n",
       " 461: 'w_16b5050',\n",
       " 462: 'w_16b7fec',\n",
       " 463: 'w_16c264e',\n",
       " 464: 'w_16dba74',\n",
       " 465: 'w_16def42',\n",
       " 466: 'w_16df050',\n",
       " 467: 'w_16dfac7',\n",
       " 468: 'w_16f4e1e',\n",
       " 469: 'w_16fa149',\n",
       " 470: 'w_171794e',\n",
       " 471: 'w_1719d81',\n",
       " 472: 'w_171ca39',\n",
       " 473: 'w_171dc55',\n",
       " 474: 'w_1728040',\n",
       " 475: 'w_17338da',\n",
       " 476: 'w_1759e4e',\n",
       " 477: 'w_175d6fa',\n",
       " 478: 'w_177d88e',\n",
       " 479: 'w_178144f',\n",
       " 480: 'w_1788910',\n",
       " 481: 'w_179c9f0',\n",
       " 482: 'w_17a108a',\n",
       " 483: 'w_17a3a21',\n",
       " 484: 'w_17a4a41',\n",
       " 485: 'w_17b0d3a',\n",
       " 486: 'w_17ba5e4',\n",
       " 487: 'w_17be6f2',\n",
       " 488: 'w_17c9df5',\n",
       " 489: 'w_17d6235',\n",
       " 490: 'w_17dd986',\n",
       " 491: 'w_17e8846',\n",
       " 492: 'w_17f5d1d',\n",
       " 493: 'w_17fef9b',\n",
       " 494: 'w_180e241',\n",
       " 495: 'w_181ab06',\n",
       " 496: 'w_1834b49',\n",
       " 497: 'w_185044d',\n",
       " 498: 'w_185bc11',\n",
       " 499: 'w_18645ff',\n",
       " 500: 'w_18666da',\n",
       " 501: 'w_186d294',\n",
       " 502: 'w_1870783',\n",
       " 503: 'w_187de67',\n",
       " 504: 'w_1887b5a',\n",
       " 505: 'w_18934ab',\n",
       " 506: 'w_18a06fd',\n",
       " 507: 'w_18aafe8',\n",
       " 508: 'w_18c481a',\n",
       " 509: 'w_18ca0f1',\n",
       " 510: 'w_18f9d19',\n",
       " 511: 'w_190375b',\n",
       " 512: 'w_190b9bb',\n",
       " 513: 'w_191bce3',\n",
       " 514: 'w_1920193',\n",
       " 515: 'w_1930599',\n",
       " 516: 'w_1932830',\n",
       " 517: 'w_193bf22',\n",
       " 518: 'w_193f83c',\n",
       " 519: 'w_19410fe',\n",
       " 520: 'w_194bea2',\n",
       " 521: 'w_19671ad',\n",
       " 522: 'w_197979e',\n",
       " 523: 'w_1995d15',\n",
       " 524: 'w_19a0b30',\n",
       " 525: 'w_19bd11d',\n",
       " 526: 'w_19c50fa',\n",
       " 527: 'w_19dfa67',\n",
       " 528: 'w_19f365e',\n",
       " 529: 'w_19f507e',\n",
       " 530: 'w_19fb122',\n",
       " 531: 'w_1a071a3',\n",
       " 532: 'w_1a151e5',\n",
       " 533: 'w_1a20162',\n",
       " 534: 'w_1a31542',\n",
       " 535: 'w_1a619db',\n",
       " 536: 'w_1a657fc',\n",
       " 537: 'w_1a70f3a',\n",
       " 538: 'w_1a7ccaf',\n",
       " 539: 'w_1a874a6',\n",
       " 540: 'w_1a96d7b',\n",
       " 541: 'w_1a9e018',\n",
       " 542: 'w_1ab568f',\n",
       " 543: 'w_1af6b9a',\n",
       " 544: 'w_1afed1e',\n",
       " 545: 'w_1afff3f',\n",
       " 546: 'w_1b00c27',\n",
       " 547: 'w_1b04c3c',\n",
       " 548: 'w_1b0c4b7',\n",
       " 549: 'w_1b0db58',\n",
       " 550: 'w_1b1dd05',\n",
       " 551: 'w_1b2bf0f',\n",
       " 552: 'w_1b3baf7',\n",
       " 553: 'w_1b3c3a4',\n",
       " 554: 'w_1b4b202',\n",
       " 555: 'w_1b4bb29',\n",
       " 556: 'w_1b50676',\n",
       " 557: 'w_1b51678',\n",
       " 558: 'w_1b5b199',\n",
       " 559: 'w_1b5fd1b',\n",
       " 560: 'w_1b6f30f',\n",
       " 561: 'w_1b6f6dc',\n",
       " 562: 'w_1b70bda',\n",
       " 563: 'w_1b70f3f',\n",
       " 564: 'w_1b77e4f',\n",
       " 565: 'w_1b7eaad',\n",
       " 566: 'w_1b8f126',\n",
       " 567: 'w_1baf8df',\n",
       " 568: 'w_1bbc982',\n",
       " 569: 'w_1bd2d91',\n",
       " 570: 'w_1be76f5',\n",
       " 571: 'w_1c2e409',\n",
       " 572: 'w_1c39fb1',\n",
       " 573: 'w_1c47899',\n",
       " 574: 'w_1c55cc3',\n",
       " 575: 'w_1c63738',\n",
       " 576: 'w_1c6465a',\n",
       " 577: 'w_1ca7433',\n",
       " 578: 'w_1ca9ab1',\n",
       " 579: 'w_1cb0ffc',\n",
       " 580: 'w_1ccd2a1',\n",
       " 581: 'w_1ccea93',\n",
       " 582: 'w_1cfebce',\n",
       " 583: 'w_1d0830e',\n",
       " 584: 'w_1d1fffe',\n",
       " 585: 'w_1d2d323',\n",
       " 586: 'w_1d2ed91',\n",
       " 587: 'w_1d35a02',\n",
       " 588: 'w_1d4e949',\n",
       " 589: 'w_1d532b4',\n",
       " 590: 'w_1d55e83',\n",
       " 591: 'w_1d6a51b',\n",
       " 592: 'w_1d6a9f7',\n",
       " 593: 'w_1d7fd7d',\n",
       " 594: 'w_1d830c2',\n",
       " 595: 'w_1d8d7c3',\n",
       " 596: 'w_1d9592f',\n",
       " 597: 'w_1da3327',\n",
       " 598: 'w_1da93f8',\n",
       " 599: 'w_1daae48',\n",
       " 600: 'w_1dc7d3a',\n",
       " 601: 'w_1dd336a',\n",
       " 602: 'w_1de6148',\n",
       " 603: 'w_1df2383',\n",
       " 604: 'w_1dff836',\n",
       " 605: 'w_1e1e5d9',\n",
       " 606: 'w_1e283bb',\n",
       " 607: 'w_1e286e0',\n",
       " 608: 'w_1e3b8e8',\n",
       " 609: 'w_1e3caae',\n",
       " 610: 'w_1e3e9a7',\n",
       " 611: 'w_1e81b43',\n",
       " 612: 'w_1e85eea',\n",
       " 613: 'w_1e99233',\n",
       " 614: 'w_1e9caad',\n",
       " 615: 'w_1ea5d96',\n",
       " 616: 'w_1ea8997',\n",
       " 617: 'w_1eb67e3',\n",
       " 618: 'w_1ebcda9',\n",
       " 619: 'w_1ecca2d',\n",
       " 620: 'w_1ee38d5',\n",
       " 621: 'w_1ef6c12',\n",
       " 622: 'w_1efb6fa',\n",
       " 623: 'w_1efbb8e',\n",
       " 624: 'w_1f0cf0a',\n",
       " 625: 'w_1f1774e',\n",
       " 626: 'w_1f1cee1',\n",
       " 627: 'w_1f41b98',\n",
       " 628: 'w_1f429ff',\n",
       " 629: 'w_1f62b56',\n",
       " 630: 'w_1f6de0b',\n",
       " 631: 'w_1f78a1e',\n",
       " 632: 'w_1f7c696',\n",
       " 633: 'w_1f7e291',\n",
       " 634: 'w_1f85037',\n",
       " 635: 'w_1f8621d',\n",
       " 636: 'w_1f8c439',\n",
       " 637: 'w_1faaf06',\n",
       " 638: 'w_1faf1e4',\n",
       " 639: 'w_1fb652d',\n",
       " 640: 'w_1fc42e2',\n",
       " 641: 'w_1fc4625',\n",
       " 642: 'w_1fe6c6e',\n",
       " 643: 'w_1fecb34',\n",
       " 644: 'w_1ff111d',\n",
       " 645: 'w_1ff1582',\n",
       " 646: 'w_1ff168e',\n",
       " 647: 'w_1ff410a',\n",
       " 648: 'w_1ffc4ab',\n",
       " 649: 'w_2009f8b',\n",
       " 650: 'w_203042e',\n",
       " 651: 'w_2034344',\n",
       " 652: 'w_2036a57',\n",
       " 653: 'w_205708f',\n",
       " 654: 'w_2059146',\n",
       " 655: 'w_207f153',\n",
       " 656: 'w_208db25',\n",
       " 657: 'w_20930e7',\n",
       " 658: 'w_20950a9',\n",
       " 659: 'w_20ad973',\n",
       " 660: 'w_20baeef',\n",
       " 661: 'w_20c0bc0',\n",
       " 662: 'w_20df2c5',\n",
       " 663: 'w_20dfb69',\n",
       " 664: 'w_20edfc3',\n",
       " 665: 'w_20eeb29',\n",
       " 666: 'w_2103ca8',\n",
       " 667: 'w_210b625',\n",
       " 668: 'w_210caac',\n",
       " 669: 'w_2112103',\n",
       " 670: 'w_2117e10',\n",
       " 671: 'w_2136d08',\n",
       " 672: 'w_2137c6f',\n",
       " 673: 'w_213fb07',\n",
       " 674: 'w_2148753',\n",
       " 675: 'w_214e081',\n",
       " 676: 'w_21591ba',\n",
       " 677: 'w_21666ad',\n",
       " 678: 'w_217fc01',\n",
       " 679: 'w_218fe4a',\n",
       " 680: 'w_21a7dac',\n",
       " 681: 'w_21ae2d7',\n",
       " 682: 'w_21b2790',\n",
       " 683: 'w_21b3c7e',\n",
       " 684: 'w_21b94e3',\n",
       " 685: 'w_21bb5bd',\n",
       " 686: 'w_21d5943',\n",
       " 687: 'w_21ecbf3',\n",
       " 688: 'w_21f1129',\n",
       " 689: 'w_21fd105',\n",
       " 690: 'w_2211e6d',\n",
       " 691: 'w_222ba28',\n",
       " 692: 'w_224bfc5',\n",
       " 693: 'w_227e394',\n",
       " 694: 'w_2284d86',\n",
       " 695: 'w_228c7ee',\n",
       " 696: 'w_2296421',\n",
       " 697: 'w_22a168a',\n",
       " 698: 'w_22b8752',\n",
       " 699: 'w_22cdc5f',\n",
       " 700: 'w_22d96e7',\n",
       " 701: 'w_22e82fa',\n",
       " 702: 'w_22f2567',\n",
       " 703: 'w_22f46ab',\n",
       " 704: 'w_232f528',\n",
       " 705: 'w_2330989',\n",
       " 706: 'w_234713b',\n",
       " 707: 'w_2349681',\n",
       " 708: 'w_234d686',\n",
       " 709: 'w_2362d7f',\n",
       " 710: 'w_2365d55',\n",
       " 711: 'w_23852a0',\n",
       " 712: 'w_23a388d',\n",
       " 713: 'w_23bfd0a',\n",
       " 714: 'w_23ce00e',\n",
       " 715: 'w_23d4815',\n",
       " 716: 'w_23e1d57',\n",
       " 717: 'w_24076b5',\n",
       " 718: 'w_2409871',\n",
       " 719: 'w_240cbf9',\n",
       " 720: 'w_2424e82',\n",
       " 721: 'w_242fb46',\n",
       " 722: 'w_243b654',\n",
       " 723: 'w_244ab03',\n",
       " 724: 'w_244e953',\n",
       " 725: 'w_245ac74',\n",
       " 726: 'w_248381e',\n",
       " 727: 'w_249346b',\n",
       " 728: 'w_2495755',\n",
       " 729: 'w_2497490',\n",
       " 730: 'w_24b2561',\n",
       " 731: 'w_24b5070',\n",
       " 732: 'w_24c6ff8',\n",
       " 733: 'w_24c76d8',\n",
       " 734: 'w_24ca106',\n",
       " 735: 'w_24d3109',\n",
       " 736: 'w_24e9b5d',\n",
       " 737: 'w_2500327',\n",
       " 738: 'w_25085e0',\n",
       " 739: 'w_25183b8',\n",
       " 740: 'w_252d315',\n",
       " 741: 'w_2548d54',\n",
       " 742: 'w_2570b49',\n",
       " 743: 'w_257e223',\n",
       " 744: 'w_2592960',\n",
       " 745: 'w_2597710',\n",
       " 746: 'w_25b2b3d',\n",
       " 747: 'w_25d662d',\n",
       " 748: 'w_25d7e08',\n",
       " 749: 'w_25e04d9',\n",
       " 750: 'w_25f1a4e',\n",
       " 751: 'w_260a2e7',\n",
       " 752: 'w_260b2ac',\n",
       " 753: 'w_260e1d7',\n",
       " 754: 'w_260ff2c',\n",
       " 755: 'w_261878d',\n",
       " 756: 'w_2623921',\n",
       " 757: 'w_2623b69',\n",
       " 758: 'w_262c32f',\n",
       " 759: 'w_262ec5b',\n",
       " 760: 'w_26301f8',\n",
       " 761: 'w_263bd97',\n",
       " 762: 'w_263fcb0',\n",
       " 763: 'w_2644b11',\n",
       " 764: 'w_2645f4d',\n",
       " 765: 'w_264c2e1',\n",
       " 766: 'w_2652d72',\n",
       " 767: 'w_265ac62',\n",
       " 768: 'w_267c7e3',\n",
       " 769: 'w_268addf',\n",
       " 770: 'w_26923f7',\n",
       " 771: 'w_2694603',\n",
       " 772: 'w_26a55ed',\n",
       " 773: 'w_26aeb61',\n",
       " 774: 'w_26b24d4',\n",
       " 775: 'w_26ba5fd',\n",
       " 776: 'w_26c0ffd',\n",
       " 777: 'w_26db444',\n",
       " 778: 'w_26e4f44',\n",
       " 779: 'w_26f7c39',\n",
       " 780: 'w_270f505',\n",
       " 781: 'w_2719f85',\n",
       " 782: 'w_27272a5',\n",
       " 783: 'w_274397d',\n",
       " 784: 'w_2745292',\n",
       " 785: 'w_274d994',\n",
       " 786: 'w_274f6db',\n",
       " 787: 'w_2757c07',\n",
       " 788: 'w_27597ff',\n",
       " 789: 'w_2759bb6',\n",
       " 790: 'w_276390d',\n",
       " 791: 'w_276d61d',\n",
       " 792: 'w_277d911',\n",
       " 793: 'w_27a6304',\n",
       " 794: 'w_27aa28c',\n",
       " 795: 'w_27b7295',\n",
       " 796: 'w_27be996',\n",
       " 797: 'w_27d6aac',\n",
       " 798: 'w_27fa393',\n",
       " 799: 'w_27fd7e3',\n",
       " 800: 'w_2807565',\n",
       " 801: 'w_2812e0d',\n",
       " 802: 'w_281a8cd',\n",
       " 803: 'w_28218e1',\n",
       " 804: 'w_283ceeb',\n",
       " 805: 'w_2843a30',\n",
       " 806: 'w_2852461',\n",
       " 807: 'w_2856c57',\n",
       " 808: 'w_28589bc',\n",
       " 809: 'w_2858e46',\n",
       " 810: 'w_286d2cc',\n",
       " 811: 'w_289778b',\n",
       " 812: 'w_28a16b0',\n",
       " 813: 'w_28c1ced',\n",
       " 814: 'w_28c330c',\n",
       " 815: 'w_28cb717',\n",
       " 816: 'w_28d57ec',\n",
       " 817: 'w_28df1bb',\n",
       " 818: 'w_28f572d',\n",
       " 819: 'w_2902e69',\n",
       " 820: 'w_290399a',\n",
       " 821: 'w_291b418',\n",
       " 822: 'w_291cba5',\n",
       " 823: 'w_2926c77',\n",
       " 824: 'w_292956e',\n",
       " 825: 'w_293431f',\n",
       " 826: 'w_2964e0b',\n",
       " 827: 'w_2972f31',\n",
       " 828: 'w_297503e',\n",
       " 829: 'w_297e53a',\n",
       " 830: 'w_2980f85',\n",
       " 831: 'w_298a035',\n",
       " 832: 'w_298f605',\n",
       " 833: 'w_29a8580',\n",
       " 834: 'w_29af733',\n",
       " 835: 'w_29c0caf',\n",
       " 836: 'w_29c88c2',\n",
       " 837: 'w_29cde7c',\n",
       " 838: 'w_29d806a',\n",
       " 839: 'w_29e5e8e',\n",
       " 840: 'w_29e8496',\n",
       " 841: 'w_29e87c9',\n",
       " 842: 'w_2a0e817',\n",
       " 843: 'w_2a1a012',\n",
       " 844: 'w_2a1a125',\n",
       " 845: 'w_2a2bcf1',\n",
       " 846: 'w_2a6d5ee',\n",
       " 847: 'w_2a7603f',\n",
       " 848: 'w_2a7c1af',\n",
       " 849: 'w_2a7f00f',\n",
       " 850: 'w_2a946f2',\n",
       " 851: 'w_2a98962',\n",
       " 852: 'w_2aaa3b5',\n",
       " 853: 'w_2ab34d0',\n",
       " 854: 'w_2ac2bac',\n",
       " 855: 'w_2ac6611',\n",
       " 856: 'w_2ad05e9',\n",
       " 857: 'w_2ae40f9',\n",
       " 858: 'w_2af46a8',\n",
       " 859: 'w_2b069ba',\n",
       " 860: 'w_2b17316',\n",
       " 861: 'w_2b1b04e',\n",
       " 862: 'w_2b388fe',\n",
       " 863: 'w_2b39f31',\n",
       " 864: 'w_2b47174',\n",
       " 865: 'w_2b49489',\n",
       " 866: 'w_2b4b82e',\n",
       " 867: 'w_2b50adf',\n",
       " 868: 'w_2b65b34',\n",
       " 869: 'w_2b7f65a',\n",
       " 870: 'w_2b979e6',\n",
       " 871: 'w_2ba6978',\n",
       " 872: 'w_2c0cfe8',\n",
       " 873: 'w_2c0f96c',\n",
       " 874: 'w_2c1a562',\n",
       " 875: 'w_2c29146',\n",
       " 876: 'w_2c2e6b9',\n",
       " 877: 'w_2c3768d',\n",
       " 878: 'w_2c3c217',\n",
       " 879: 'w_2c3f556',\n",
       " 880: 'w_2c5fe7e',\n",
       " 881: 'w_2c7deff',\n",
       " 882: 'w_2c94198',\n",
       " 883: 'w_2ca9282',\n",
       " 884: 'w_2cabd62',\n",
       " 885: 'w_2cd7341',\n",
       " 886: 'w_2cdde18',\n",
       " 887: 'w_2d0cfc1',\n",
       " 888: 'w_2d1592c',\n",
       " 889: 'w_2d1d67a',\n",
       " 890: 'w_2d3ef19',\n",
       " 891: 'w_2d5492b',\n",
       " 892: 'w_2d5b0e1',\n",
       " 893: 'w_2d5dc31',\n",
       " 894: 'w_2d6596f',\n",
       " 895: 'w_2d6bb89',\n",
       " 896: 'w_2d7c2dd',\n",
       " 897: 'w_2d99567',\n",
       " 898: 'w_2db0644',\n",
       " 899: 'w_2dd6b62',\n",
       " 900: 'w_2ddcce9',\n",
       " 901: 'w_2de1c5c',\n",
       " 902: 'w_2df1d85',\n",
       " 903: 'w_2df37cc',\n",
       " 904: 'w_2df85e7',\n",
       " 905: 'w_2e075b2',\n",
       " 906: 'w_2e1416e',\n",
       " 907: 'w_2e18226',\n",
       " 908: 'w_2e21094',\n",
       " 909: 'w_2e231f4',\n",
       " 910: 'w_2e29743',\n",
       " 911: 'w_2e35d7c',\n",
       " 912: 'w_2e374c0',\n",
       " 913: 'w_2e3e30d',\n",
       " 914: 'w_2e45865',\n",
       " 915: 'w_2e4af64',\n",
       " 916: 'w_2e4b740',\n",
       " 917: 'w_2e4cb98',\n",
       " 918: 'w_2e54183',\n",
       " 919: 'w_2e5ad54',\n",
       " 920: 'w_2e5d992',\n",
       " 921: 'w_2e69752',\n",
       " 922: 'w_2e706fc',\n",
       " 923: 'w_2e9d1b5',\n",
       " 924: 'w_2e9ed59',\n",
       " 925: 'w_2ec0a71',\n",
       " 926: 'w_2ed0acc',\n",
       " 927: 'w_2ed0d2f',\n",
       " 928: 'w_2ed1e39',\n",
       " 929: 'w_2eec458',\n",
       " 930: 'w_2ef6741',\n",
       " 931: 'w_2ef9c36',\n",
       " 932: 'w_2efa6ab',\n",
       " 933: 'w_2f0416b',\n",
       " 934: 'w_2f0f74c',\n",
       " 935: 'w_2f1488c',\n",
       " 936: 'w_2f2c0d6',\n",
       " 937: 'w_2f350be',\n",
       " 938: 'w_2f3badb',\n",
       " 939: 'w_2f4be30',\n",
       " 940: 'w_2f5652a',\n",
       " 941: 'w_2f5caa9',\n",
       " 942: 'w_2f67f0a',\n",
       " 943: 'w_2f6d4a8',\n",
       " 944: 'w_2f702db',\n",
       " 945: 'w_2f74ff3',\n",
       " 946: 'w_2f79ae3',\n",
       " 947: 'w_2f841ea',\n",
       " 948: 'w_2f87cc7',\n",
       " 949: 'w_2f8895a',\n",
       " 950: 'w_2f8de4f',\n",
       " 951: 'w_2f8eda5',\n",
       " 952: 'w_2f94559',\n",
       " 953: 'w_2f9b02c',\n",
       " 954: 'w_2fc317c',\n",
       " 955: 'w_2fc775e',\n",
       " 956: 'w_2fcfc71',\n",
       " 957: 'w_2fdb049',\n",
       " 958: 'w_2fdf4cb',\n",
       " 959: 'w_2fe1c3f',\n",
       " 960: 'w_2fec5ea',\n",
       " 961: 'w_2ff0834',\n",
       " 962: 'w_3002b59',\n",
       " 963: 'w_301f728',\n",
       " 964: 'w_302799d',\n",
       " 965: 'w_303a3c4',\n",
       " 966: 'w_3040ecd',\n",
       " 967: 'w_305456a',\n",
       " 968: 'w_3057209',\n",
       " 969: 'w_3067220',\n",
       " 970: 'w_30719c8',\n",
       " 971: 'w_3079e26',\n",
       " 972: 'w_307e5e9',\n",
       " 973: 'w_308c7b6',\n",
       " 974: 'w_30a7b3f',\n",
       " 975: 'w_30b577d',\n",
       " 976: 'w_30f2f0f',\n",
       " 977: 'w_310226c',\n",
       " 978: 'w_3108dce',\n",
       " 979: 'w_310a26b',\n",
       " 980: 'w_310a94d',\n",
       " 981: 'w_31154fa',\n",
       " 982: 'w_31233f8',\n",
       " 983: 'w_3128adb',\n",
       " 984: 'w_3132fce',\n",
       " 985: 'w_3137898',\n",
       " 986: 'w_3137deb',\n",
       " 987: 'w_31438a5',\n",
       " 988: 'w_314bc30',\n",
       " 989: 'w_3154c82',\n",
       " 990: 'w_3155d04',\n",
       " 991: 'w_315c854',\n",
       " 992: 'w_317ae6c',\n",
       " 993: 'w_317c071',\n",
       " 994: 'w_3180b48',\n",
       " 995: 'w_31b5dd8',\n",
       " 996: 'w_31d1d50',\n",
       " 997: 'w_31e1bc1',\n",
       " 998: 'w_32015c2',\n",
       " 999: 'w_32043b0',\n",
       " ...}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_lookup = {}\n",
    "for key in allimg.class_to_idx:\n",
    "    rev_lookup[allimg.class_to_idx[key]] = key\n",
    "rev_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97bca335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T23:50:43.422895Z",
     "iopub.status.busy": "2022-03-19T23:50:43.422042Z",
     "iopub.status.idle": "2022-03-19T23:53:49.890946Z",
     "shell.execute_reply": "2022-03-19T23:53:49.891383Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.885543Z"
    },
    "papermill": {
     "duration": 186.538346,
     "end_time": "2022-03-19T23:53:49.891532",
     "exception": false,
     "start_time": "2022-03-19T23:50:43.353186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['new_whale', 'w_6caa59f', 'w_22d96e7', 'w_772c726', 'w_8b943ef'],\n",
       " ['new_whale', 'w_e3956f5', 'w_22d96e7', 'w_f5bf6df', 'w_8af65ed'],\n",
       " ['new_whale', 'w_a743e09', 'w_400791e', 'w_ae6ac74', 'w_c6c60c8'],\n",
       " ['w_9c506f6', 'w_a6703dd', 'w_59052ad', 'w_7938c79', 'w_d6aa3f3'],\n",
       " ['new_whale', 'w_92ac4b2', 'w_e145c7a', 'w_e2372d6', 'w_799b208'],\n",
       " ['new_whale', 'w_0e7ec27', 'w_1b6f30f', 'w_46e59f5', 'w_b4cf4b1'],\n",
       " ['w_b2bc0c9', 'w_8eae2c3', 'w_7e2eb3d', 'w_fe881f2', 'w_98bac23'],\n",
       " ['new_whale', 'w_b70c09f', 'w_50c4067', 'w_dd80742', 'w_1260eb5'],\n",
       " ['new_whale', 'w_715b1b5', 'w_f35e494', 'w_a13f1d0', 'w_a7e3d55'],\n",
       " ['new_whale', 'w_b60ef24', 'w_d09a047', 'w_6f74177', 'w_72f3685']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = []\n",
    "for step, (images, labels) in enumerate(submission_loader):\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        preds_by_image = m(images).argsort()\n",
    "        for t in preds_by_image:\n",
    "            # list top 1-5 best classes\n",
    "            liked = t.tolist()[-5:][::-1]\n",
    "            # convert class index to whale ID\n",
    "            all_preds.append(list(map(lambda nid: rev_lookup[nid], liked)))\n",
    "all_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc853edc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T23:53:50.025197Z",
     "iopub.status.busy": "2022-03-19T23:53:50.024478Z",
     "iopub.status.idle": "2022-03-19T23:53:50.729740Z",
     "shell.execute_reply": "2022-03-19T23:53:50.730181Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.88745Z"
    },
    "papermill": {
     "duration": 0.774931,
     "end_time": "2022-03-19T23:53:50.730358",
     "exception": false,
     "start_time": "2022-03-19T23:53:49.955427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image,Id\r\n",
      "00028a005.jpg,new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\r\n",
      "000dcf7d8.jpg,new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\r\n",
      "000e7c7df.jpg,new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\r\n",
      "0019c34f4.jpg,new_whale w_23a388d w_9b5109b w_9c506f6 w_0369a5c\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 5 ../input/humpback-whale-identification/sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8634b958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T23:53:50.863597Z",
     "iopub.status.busy": "2022-03-19T23:53:50.862798Z",
     "iopub.status.idle": "2022-03-19T23:53:50.893141Z",
     "shell.execute_reply": "2022-03-19T23:53:50.892747Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.889322Z"
    },
    "papermill": {
     "duration": 0.098276,
     "end_time": "2022-03-19T23:53:50.893259",
     "exception": false,
     "start_time": "2022-03-19T23:53:50.794983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('submission.csv', 'w') as opfile:\n",
    "    wrt = csv.writer(opfile)\n",
    "    wrt.writerow(['Image', 'Id'])\n",
    "    for idx in range(0, len(filenames)):\n",
    "        wrt.writerow([\n",
    "            filenames[idx],\n",
    "            ' '.join(all_preds[idx]),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ba0c4e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-19T23:53:51.027419Z",
     "iopub.status.busy": "2022-03-19T23:53:51.026710Z",
     "iopub.status.idle": "2022-03-19T23:53:51.865219Z",
     "shell.execute_reply": "2022-03-19T23:53:51.865723Z",
     "shell.execute_reply.started": "2022-03-19T22:32:20.891716Z"
    },
    "papermill": {
     "duration": 0.908256,
     "end_time": "2022-03-19T23:53:51.865888",
     "exception": false,
     "start_time": "2022-03-19T23:53:50.957632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 5 submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4533.963868,
   "end_time": "2022-03-19T23:53:54.520452",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-19T22:38:20.556584",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
