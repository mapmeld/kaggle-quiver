{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# based on https://www.kaggle.com/piantic/how-to-finetuning-models-pytorch-xla-tpu\n\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-18T06:22:30.771748Z","iopub.execute_input":"2022-03-18T06:22:30.772398Z","iopub.status.idle":"2022-03-18T06:22:30.776756Z","shell.execute_reply.started":"2022-03-18T06:22:30.772359Z","shell.execute_reply":"2022-03-18T06:22:30.775963Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"! ls ../input/cassava-disease","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:30.778045Z","iopub.execute_input":"2022-03-18T06:22:30.778686Z","iopub.status.idle":"2022-03-18T06:22:31.486408Z","shell.execute_reply.started":"2022-03-18T06:22:30.778631Z","shell.execute_reply":"2022-03-18T06:22:31.485632Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"! rm -rf ./train\n! unzip ../input/cassava-disease/train.zip > abc","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:31.490027Z","iopub.execute_input":"2022-03-18T06:22:31.490275Z","iopub.status.idle":"2022-03-18T06:22:38.971867Z","shell.execute_reply.started":"2022-03-18T06:22:31.490249Z","shell.execute_reply":"2022-03-18T06:22:38.970934Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"! ls train","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:38.973546Z","iopub.execute_input":"2022-03-18T06:22:38.973826Z","iopub.status.idle":"2022-03-18T06:22:39.674181Z","shell.execute_reply.started":"2022-03-18T06:22:38.973792Z","shell.execute_reply":"2022-03-18T06:22:39.673336Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import datasets, transforms\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:39.677675Z","iopub.execute_input":"2022-03-18T06:22:39.678384Z","iopub.status.idle":"2022-03-18T06:22:39.683499Z","shell.execute_reply.started":"2022-03-18T06:22:39.678349Z","shell.execute_reply":"2022-03-18T06:22:39.682543Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(255),\n    transforms.CenterCrop(224),\n    transforms.ToTensor()\n])\n\nallimg = datasets.ImageFolder('./train', transform=transform)\n\nvalidation_split = 0.25\ndataset_size = len(allimg)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nnp.random.seed(101)\nnp.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:39.684963Z","iopub.execute_input":"2022-03-18T06:22:39.685440Z","iopub.status.idle":"2022-03-18T06:22:39.728976Z","shell.execute_reply.started":"2022-03-18T06:22:39.685405Z","shell.execute_reply":"2022-03-18T06:22:39.727949Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(allimg, batch_size=16, \n                                           sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(allimg, batch_size=16,\n                                                sampler=valid_sampler)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:39.730233Z","iopub.execute_input":"2022-03-18T06:22:39.730912Z","iopub.status.idle":"2022-03-18T06:22:39.737656Z","shell.execute_reply.started":"2022-03-18T06:22:39.730853Z","shell.execute_reply":"2022-03-18T06:22:39.736757Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_loader:\n    print(images[0])\n    print(labels[0])\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:39.740079Z","iopub.execute_input":"2022-03-18T06:22:39.741026Z","iopub.status.idle":"2022-03-18T06:22:39.919702Z","shell.execute_reply.started":"2022-03-18T06:22:39.740987Z","shell.execute_reply":"2022-03-18T06:22:39.918973Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from torch import nn\n\nclass CustomResNext(nn.Module):\n    def __init__(self, model_name, target_size, pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, target_size)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n    \n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n        for param in self.model.fc.parameters():\n            param.requires_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.model.parameters():\n            param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:39.921035Z","iopub.execute_input":"2022-03-18T06:22:39.921622Z","iopub.status.idle":"2022-03-18T06:22:39.931277Z","shell.execute_reply.started":"2022-03-18T06:22:39.921565Z","shell.execute_reply":"2022-03-18T06:22:39.930461Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"allimg.class_to_idx","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:39.932986Z","iopub.execute_input":"2022-03-18T06:22:39.933293Z","iopub.status.idle":"2022-03-18T06:22:39.945623Z","shell.execute_reply.started":"2022-03-18T06:22:39.933237Z","shell.execute_reply":"2022-03-18T06:22:39.944852Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"m = CustomResNext('resnext50_32x4d', len(allimg.class_to_idx.keys()))\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nm.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:39.948982Z","iopub.execute_input":"2022-03-18T06:22:39.949957Z","iopub.status.idle":"2022-03-18T06:22:40.504193Z","shell.execute_reply.started":"2022-03-18T06:22:39.949921Z","shell.execute_reply":"2022-03-18T06:22:40.503513Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduce=True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduce = reduce\n\n    def forward(self, inputs, targets):\n        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:40.505286Z","iopub.execute_input":"2022-03-18T06:22:40.505687Z","iopub.status.idle":"2022-03-18T06:22:40.514735Z","shell.execute_reply.started":"2022-03-18T06:22:40.505652Z","shell.execute_reply":"2022-03-18T06:22:40.514013Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\noptimizer = Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=1e-4, weight_decay=1e-6, amsgrad=False)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', verbose=True)\ncriterion = FocalLoss().to(device)\nbest_score = 0.\nbest_loss = np.inf\nconfig_device = \"GPU\"","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:40.515901Z","iopub.execute_input":"2022-03-18T06:22:40.516142Z","iopub.status.idle":"2022-03-18T06:22:40.526549Z","shell.execute_reply.started":"2022-03-18T06:22:40.516104Z","shell.execute_reply":"2022-03-18T06:22:40.525879Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import math\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:40.527928Z","iopub.execute_input":"2022-03-18T06:22:40.528193Z","iopub.status.idle":"2022-03-18T06:22:40.537757Z","shell.execute_reply.started":"2022-03-18T06:22:40.528158Z","shell.execute_reply":"2022-03-18T06:22:40.536988Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    scaler = GradScaler()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        with autocast():\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n            # record loss\n            losses.update(loss.item(), batch_size)\n#             if CFG.gradient_accumulation_steps > 1:\n#                 loss = loss / CFG.gradient_accumulation_steps\n            scaler.scale(loss).backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1000)\n            if (step + 1) % 1 == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % 10 == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  #'LR: {lr:.6f}  '\n                  .format(\n                   epoch+1, step, len(train_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)/len(train_loader)),\n                   grad_norm=grad_norm,\n                   #lr=scheduler.get_lr()[0],\n                   ))\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    trues = []\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        trues.append(labels.to('cpu').numpy())\n        preds.append(y_preds.softmax(1).to('cpu').numpy())\n#         if CFG.gradient_accumulation_steps > 1:\n#             loss = loss / CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if step % 10 == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}/{1}] '\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(\n                   step, len(valid_loader), batch_time=batch_time,\n                   data_time=data_time, loss=losses,\n                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n                   ))\n    trues = np.concatenate(trues)\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions, trues","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:40.539242Z","iopub.execute_input":"2022-03-18T06:22:40.539509Z","iopub.status.idle":"2022-03-18T06:22:40.561651Z","shell.execute_reply.started":"2022-03-18T06:22:40.539473Z","shell.execute_reply":"2022-03-18T06:22:40.560738Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ndef get_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:40.563323Z","iopub.execute_input":"2022-03-18T06:22:40.563613Z","iopub.status.idle":"2022-03-18T06:22:40.573031Z","shell.execute_reply.started":"2022-03-18T06:22:40.563563Z","shell.execute_reply":"2022-03-18T06:22:40.572278Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"valid_labels = []\nfor img, labels in validation_loader:\n    valid_labels += labels.tolist()\nvalid_labels[:20]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:40.575441Z","iopub.execute_input":"2022-03-18T06:22:40.576151Z","iopub.status.idle":"2022-03-18T06:22:53.709094Z","shell.execute_reply.started":"2022-03-18T06:22:40.576114Z","shell.execute_reply":"2022-03-18T06:22:53.708422Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import time\nfor epoch in range(10):\n\n    start_time = time.time()\n\n    avg_loss = train_fn(train_loader, m, criterion, optimizer, epoch, scheduler, device)\n    avg_val_loss, preds, _ = valid_fn(validation_loader, m, criterion, device)\n\n    score = get_score(valid_labels, preds.argmax(1))\n\n    elapsed = time.time() - start_time\n\n    print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n    print(f'Epoch {epoch+1} - Score: {score:.4f}')\n    \n    if score > best_score:\n        best_score = score\n        print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n        torch.save({'model': m.state_dict(), \n                        'preds': preds},\n                       'best_score.pth')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T06:22:53.710353Z","iopub.execute_input":"2022-03-18T06:22:53.710769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! rm -rf ./test\n! unzip ../input/cassava-disease/test.zip > xyz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_img = datasets.ImageFolder('./test', transform=transform)\nsubmission_loader = torch.utils.data.DataLoader(submission_img, batch_size=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = []\nfor path, idx in submission_img.imgs:\n    filenames.append(path[path.index('0/test') + 2:])\nfilenames[:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = []\nfor step, (images, labels) in enumerate(submission_loader):\n    images = images.to(device)\n    with torch.no_grad():\n        all_preds += m(images).argmax(1).tolist()\nall_preds[:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! head -n 5 ../input/cassava-disease/sample_submission_file.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rev_lookup = {}\nfor key in allimg.class_to_idx:\n    rev_lookup[allimg.class_to_idx[key]] = key\nrev_lookup","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nwith open('submission.csv', 'w') as opfile:\n    wrt = csv.writer(opfile)\n    wrt.writerow(['Category', 'Id'])\n    for idx in range(0, len(filenames)):\n        wrt.writerow([\n            rev_lookup[all_preds[idx]],\n            filenames[idx]\n        ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! head -n 5 submission.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}